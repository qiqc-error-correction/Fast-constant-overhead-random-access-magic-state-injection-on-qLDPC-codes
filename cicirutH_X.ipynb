{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "018f1acf-36c4-4bca-8ea4-94d458cdb396",
   "metadata": {},
   "outputs": [],
   "source": [
    "This first and second part and of the code is from Qianxu, the author of the paper \"Constant-overhead fault-tolerant quantum computation with reconfigurable atom arrays.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "42e9979a-a46e-4ca8-b3a9-bf2818c8339d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:37: SyntaxWarning: invalid escape sequence '\\d'\n",
      "<>:43: SyntaxWarning: invalid escape sequence '\\d'\n",
      "<>:37: SyntaxWarning: invalid escape sequence '\\d'\n",
      "<>:43: SyntaxWarning: invalid escape sequence '\\d'\n",
      "/tmp/ipykernel_45593/1907164259.py:37: SyntaxWarning: invalid escape sequence '\\d'\n",
      "  non_e_pattern = \"\\d+\\.\\d+\"\n",
      "/tmp/ipykernel_45593/1907164259.py:43: SyntaxWarning: invalid escape sequence '\\d'\n",
      "  non_e_matches = re.findall(\"\\d+\\.\\d+\", error_list[0])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import re\n",
    "import numpy as np\n",
    "import os, sys\n",
    "module_path = os.path.abspath(os.path.join('./src/'))\n",
    "if module_path not in sys.path:\n",
    "        sys.path.append(module_path)\n",
    "from ldpc.bposd_decoder import BpOsdDecoder\n",
    "from ldpc.bplsd_decoder import BpLsdDecoder\n",
    "from scipy.sparse import csc_matrix\n",
    "class BPOSD_Decoder():\n",
    "    def __init__(self, h:np.ndarray, channel_probs:np.ndarray, max_iter:int, bp_method:str, \n",
    "                ms_scaling_factor:float, osd_method:str, osd_order:int):\n",
    "        \n",
    "        self.decoder = BpOsdDecoder(\n",
    "                h,\n",
    "                channel_probs=channel_probs,\n",
    "                max_iter=max_iter,\n",
    "                bp_method=bp_method,\n",
    "                ms_scaling_factor=ms_scaling_factor,\n",
    "                osd_method=osd_method,\n",
    "                osd_order=osd_order, )\n",
    "        self.h = h\n",
    "    \n",
    "    def decode(self, synd:np.ndarray):\n",
    "        self.decoder.decode(synd)\n",
    "        return self.decoder.osdw_decoding\n",
    "def GenDecodingGraphs(detector_error_model:str, num_logicals:int):\n",
    "    items = detector_error_model.split('\\n')\n",
    "    errors = [item for item in items if 'error' in item]\n",
    "    detectors = [item.split()[1] for item in items if 'detector' in item and 'shift' not in item]\n",
    "\n",
    "    combined_detectors = detectors\n",
    "    combined_errors = []\n",
    "    for error in errors:\n",
    "        error_list = error.split()\n",
    "        #error_p = float(re.findall(\"\\d+\\.\\d+\", error_list[0])[0])\n",
    "        non_e_pattern = \"\\d+\\.\\d+\"\n",
    "        e_pattern = r'([\\d]+\\.[\\d]+e-[\\d]+)'\n",
    "        e_matches = re.findall(e_pattern, error_list[0])\n",
    "        if e_matches:\n",
    "            error_p = float(e_matches[0])\n",
    "        else:\n",
    "            non_e_matches = re.findall(\"\\d+\\.\\d+\", error_list[0])\n",
    "            error_p = float(non_e_matches[0])\n",
    "\n",
    "        detectors = error_list[1:]\n",
    "        flipped_logicals = [item for item in error_list if 'L' in item]\n",
    "        error_dict = {'p':error_p, 'detectors':detectors, 'logicals':flipped_logicals}\n",
    "        combined_errors.append(error_dict)\n",
    "    \n",
    "    # construct the joint check matrix\n",
    "    H_joint = np.zeros([len(combined_detectors), len(combined_errors)])\n",
    "    for i in range(len(combined_detectors)):\n",
    "        for j in range(len(combined_errors)):\n",
    "            if combined_detectors[i] in combined_errors[j]['detectors']:\n",
    "                H_joint[i,j] = 1\n",
    "    # construct the joint logical correction matrix\n",
    "    logicals = ['L'+str(i) for i in range(num_logicals)]\n",
    "    L_joint = np.zeros([len(logicals), len(combined_errors)])\n",
    "    for i in range(len(logicals)):\n",
    "        for j in range(len(combined_errors)):\n",
    "            if logicals[i] in combined_errors[j]['logicals']:\n",
    "                L_joint[i,j] = 1\n",
    "    \n",
    "    channel_prob_joint = [error['p'] for error in combined_errors]\n",
    "        \n",
    "    return H_joint, L_joint, channel_prob_joint\n",
    "class Matching_Decoding():\n",
    "    def __init__(self):\n",
    "        self.matching = None\n",
    "        self.L = None\n",
    "        \n",
    "    \n",
    "    def from_detector_error_model(self, dem=None, num_logicals=None):\n",
    "        # generate the decoding graphs\n",
    "        H, L, channel_prob = GenDecodingGraphs(str(dem), num_logicals=num_logicals)\n",
    "        self.L = L\n",
    "        channel_prob = np.array(channel_prob)\n",
    "        weights = np.log((1-channel_prob)/channel_prob)\n",
    "        self.matching = pymatching.Matching.from_check_matrix(csc_matrix(H), weights=weights, faults_matrix=csc_matrix(L))       \n",
    "        \n",
    "    def decode_batch1(self, detector_vals):\n",
    "        detector_historys = [1.0*detector_val for detector_val in detector_vals]\n",
    "        logical_cors = []\n",
    "        for i in range(len(detector_historys)):\n",
    "            detector_values = detector_historys[i]\n",
    "            detector_values =  detector_values.T%2\n",
    "            detector_values = detector_values.reshape(1, -1)\n",
    "            cor = self.matching.decode_batch(detector_values)\n",
    "            logical_cors.append(cor)\n",
    "\n",
    "        return np.vstack(logical_cors)\n",
    "class BPOSD_Decoding():\n",
    "    def __init__(self, decoder_params={'max_iter':100, 'bp_method':'min_sum', 'ms_scaling_factor':0.9, 'osd_method':\"osd_e\", 'osd_order':6}):\n",
    "        self.decoder = None\n",
    "        self.L = None\n",
    "        self.decoder_params = decoder_params\n",
    "    \n",
    "    def from_detector_error_model(self, dem=None, num_logicals=None):\n",
    "        # generate the decoding graphs\n",
    "        H, L, channel_prob = GenDecodingGraphs(str(dem), num_logicals=num_logicals)\n",
    "        H = H.astype(int)\n",
    "        \n",
    "        self.L = L.astype(int)\n",
    "        \n",
    "        max_iter = self.decoder_params['max_iter']\n",
    "        bp_method = self.decoder_params['bp_method']\n",
    "        ms_scaling_factor = self.decoder_params['ms_scaling_factor']\n",
    "        osd_method = self.decoder_params['osd_method']\n",
    "        osd_order = self.decoder_params['osd_order']\n",
    "        self.decoder = BPOSD_Decoder(h=H, channel_probs=channel_prob,\n",
    "                                    max_iter=max_iter,\n",
    "                                    bp_method=bp_method,\n",
    "                                    ms_scaling_factor=ms_scaling_factor,\n",
    "                                    osd_method=osd_method,\n",
    "                                    osd_order=osd_order)\n",
    "        \n",
    "    def decode_batch(self, detector_vals):\n",
    "        detector_historys = [1.0*detector_val for detector_val in detector_vals]\n",
    "        logical_cors = []\n",
    "        for i in range(len(detector_historys)):\n",
    "            detector_values = detector_historys[i]   \n",
    "            cor = self.decoder.decode(detector_values)\n",
    "            log_cor = self.L@cor%2\n",
    "            logical_cors.append(log_cor.astype(int))\n",
    "\n",
    "        return np.vstack(logical_cors)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03c3790a-7ee1-43a7-9bb5-218922297e5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6776709b-8f10-4901-bb91-aabccf824be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import networkx as nx\n",
    "from networkx.algorithms import bipartite\n",
    "import copy\n",
    "import random\n",
    "\n",
    "\n",
    "def max_degree(graph):\n",
    "    return max(list(dict(graph.degree).values()))\n",
    "\n",
    "def BipartitieGraphFromCheckMat(H):\n",
    "    num_checks, num_bits = H.shape\n",
    "    C_nodes = list(-np.arange(1, num_checks + 1))\n",
    "    V_nodes = list(np.arange(1, num_bits + 1)) # 如果是 scipy.sparse 矩阵，我们需要转换\n",
    "\n",
    "    edges = [(-(i + 1), j + 1) for i in range(num_checks) for j in range(num_bits) if H[i][j] == 1]\n",
    "    \n",
    "    G = nx.Graph()\n",
    "    G.add_nodes_from(C_nodes, bipartite=0)\n",
    "    G.add_nodes_from(V_nodes, bipartite=1)\n",
    "    G.add_edges_from(edges)\n",
    "    \n",
    "    return G\n",
    "\n",
    "def best_match(graph):\n",
    "    C_nodes = list({n for n, d in graph.nodes(data=True) if d[\"bipartite\"] == 0})\n",
    "    V_nodes = list(set(graph) - set(C_nodes))\n",
    "\n",
    "    return bipartite.matching.hopcroft_karp_matching(graph, C_nodes)\n",
    "\n",
    "# Coloration circuit\n",
    "def TransformBipartiteGraph(G):\n",
    "    # transform any bipartite graph to a symmetric one by adding dummy vertices and edges\n",
    "    G_s = copy.deepcopy(G)\n",
    "    C_nodes = list({n for n, d in G.nodes(data=True) if d[\"bipartite\"] == 0})\n",
    "    V_nodes = list(set(G) - set(C_nodes))\n",
    "    \n",
    "    # Suppose C_nodes all have degree Delta_c, and # V_nodes > # C_nodes\n",
    "    # Add dummy vertices to C_nodes\n",
    "    C_nodes_dummy = list(-np.arange((len(C_nodes) + 1), len(V_nodes) + 1))\n",
    "    G_s.add_nodes_from(C_nodes_dummy, bipartite=0)\n",
    "    \n",
    "    # Add dummy edges between edges with degree < Delta_c\n",
    "    Delta = max_degree(G_s)\n",
    "#     print('max degree:', Delta)\n",
    "    open_degree_nodes = copy.deepcopy(dict((node, degree) for node, degree in dict(G_s.degree()).items() if degree < Delta))\n",
    "            \n",
    "    while len(open_degree_nodes) > 0:       \n",
    "        for node1 in list(open_degree_nodes.keys()):\n",
    "            if node1 < 0:\n",
    "                c_node = node1\n",
    "                for node2 in list(open_degree_nodes.keys()):\n",
    "                    if node2 > 0:\n",
    "                        v_node = node2\n",
    "                        if not G_s.has_edge(c_node, v_node):\n",
    "                            G_s.add_edge(c_node, v_node)\n",
    "                            \n",
    "                            if open_degree_nodes[c_node] + 1 == Delta:\n",
    "                                open_degree_nodes.pop(c_node)\n",
    "                            else:\n",
    "                                open_degree_nodes[c_node] = open_degree_nodes[c_node] + 1\n",
    "\n",
    "                            if open_degree_nodes[v_node] + 1 == Delta:\n",
    "                                open_degree_nodes.pop(v_node)\n",
    "                            else:\n",
    "                                open_degree_nodes[v_node] = open_degree_nodes[v_node] + 1\n",
    "                            \n",
    "                            break            \n",
    "                        \n",
    "            \n",
    "    return G_s\n",
    "\n",
    "\n",
    "def edge_corloring(graph):\n",
    "    matches_list = []\n",
    "    g = copy.deepcopy(graph)\n",
    "    g_s = TransformBipartiteGraph(g)\n",
    "    \n",
    "    number_colors = max_degree(g_s)\n",
    "    \n",
    "    C_nodes = list({n for n, d in g.nodes(data=True) if d[\"bipartite\"] == 0})\n",
    "    V_nodes = list(set(g) - set(C_nodes))\n",
    "    \n",
    "    C_nodes_s = list({n for n, d in g_s.nodes(data=True) if d[\"bipartite\"] == 0})\n",
    "    V_nodes_s = list(set(g_s) - set(C_nodes_s))\n",
    "\n",
    "    while len(g_s.edges()) > 0:\n",
    "#         print('NEXT COLOR')\n",
    "        bm=best_match(g_s)\n",
    "#         print(bm)\n",
    "#         matches_list.append(bm)\n",
    "        \n",
    "        # find the uniqe edges\n",
    "        unique_match = dict((c_node, bm[c_node]) for c_node in bm if c_node in C_nodes)\n",
    "        edges_list = [(c_node, bm[c_node]) for c_node in bm if c_node in C_nodes_s]\n",
    "        matches_list.append(unique_match)\n",
    "        \n",
    "        g_s.remove_edges_from(edges_list)\n",
    "#     assert len(g.edges()) == 0\n",
    "        \n",
    "    return matches_list\n",
    "\n",
    "def ColorationCircuit(H):\n",
    "    G = BipartitieGraphFromCheckMat(H)\n",
    "    matches_list = edge_corloring(G)\n",
    "    \n",
    "    scheduling_list = []\n",
    "    for match in matches_list:\n",
    "        scheduling_list.append(dict((-c_node - 1, match[c_node] - 1) for c_node in match if (match[c_node] - 1) in list(np.where(H[-c_node - 1,:] == 1)[0])))\n",
    "    \n",
    "    return scheduling_list\n",
    "\n",
    "\n",
    "# Random circuit\n",
    "def RandomCircuit(H):\n",
    "    # Obtain a random scheduling \n",
    "    rand_scheduling_seed = 30000\n",
    "    num_checks, num_bits = H.shape\n",
    "    max_stab_w = max([int(np.sum(H[i,:])) for i in range(num_checks)])\n",
    "    scheduling_list = [list(np.where(H[ancilla_index,:] == 1)[0]) for ancilla_index in range(num_checks)]\n",
    "    [random.Random(i + rand_scheduling_seed).shuffle(scheduling_list[i]) for i in range(len(scheduling_list))]\n",
    "    \n",
    "    schedulings = []\n",
    "    for time_step in range(max_stab_w):\n",
    "        scheduling = {}\n",
    "        for ancilla_index in range(num_checks):\n",
    "            if len(scheduling_list[ancilla_index]) >= time_step + 1:\n",
    "                scheduling[ancilla_index] = scheduling_list[ancilla_index][time_step]\n",
    "        schedulings.append(scheduling)\n",
    "    return schedulings\n",
    "\n",
    "\n",
    "\n",
    "# ColorProductCircuit\n",
    "def QubitIndexToPos(q_index, n_C, n_V):\n",
    "    if q_index <= n_V**2 - 1:\n",
    "        i = q_index//n_V\n",
    "        j = q_index - i*n_V\n",
    "        return i, j + n_C\n",
    "    else:\n",
    "        q_index -= n_V**2\n",
    "        i = q_index//n_C\n",
    "        j = q_index - i*n_C\n",
    "        return i + n_V, j   \n",
    "    \n",
    "def XcheckIndexToPos(X_index, n_C, n_V):\n",
    "    i = X_index//n_V\n",
    "    j = X_index - i*n_V\n",
    "    \n",
    "    return n_V + i, n_C + j\n",
    "\n",
    "def ZcheckIndexToPos(Z_index, n_C, n_V):\n",
    "    i = Z_index//n_C\n",
    "    j = Z_index - i*n_C\n",
    "    \n",
    "    return i, j\n",
    "\n",
    "def GetPosToQubitIndexMap(n_C, n_V):\n",
    "    n_q = (n_C)**2 + (n_V)**2\n",
    "    map = {}\n",
    "    for i in range(n_q):\n",
    "        q_pos = QubitIndexToPos(i, n_C, n_V)\n",
    "        map[q_pos] = i\n",
    "    return map\n",
    "\n",
    "def GetPosToZCheckIndexMap(n_C, n_V):\n",
    "    n_Z = n_V*n_C\n",
    "    map = {}\n",
    "    for i in range(n_Z):\n",
    "        q_pos = ZcheckIndexToPos(i, n_C, n_V)\n",
    "        map[q_pos] = i\n",
    "    return map\n",
    "\n",
    "def GetPosToXCheckIndexMap(n_C, n_V):\n",
    "    n_X = n_C*n_V\n",
    "    map = {}\n",
    "    for i in range(n_X):\n",
    "        q_pos = XcheckIndexToPos(i, n_C, n_V)\n",
    "        map[q_pos] = i\n",
    "    return map\n",
    "\n",
    "\n",
    "def ClassicalCheckFromQuantumCheck(h, check_type):\n",
    "    n = h.shape[1]\n",
    "    n0 = int(np.sqrt(n/25))\n",
    "    n_C, n_V = int(3*n0), int(4*n0)\n",
    "    \n",
    "    q_pos_index_map = GetPosToQubitIndexMap(n_C, n_V)\n",
    "    Z_pos_index_map = GetPosToZCheckIndexMap(n_C, n_V)\n",
    "    X_pos_index_map = GetPosToXCheckIndexMap(n_C, n_V)\n",
    "        \n",
    "    if check_type == 'Z':\n",
    "        row_Zchecks = [Z_pos_index_map[0, i] for i in range(n_C)]\n",
    "        row_qubits = [q_pos_index_map[0, i + n_C] for i in range(n_V)]\n",
    "\n",
    "        H = np.zeros([len(row_Zchecks), len(row_qubits)])\n",
    "\n",
    "        for i in range(len(row_Zchecks)):\n",
    "            for j in range(len(row_qubits)):\n",
    "                H[i,j] = h[row_Zchecks[i], row_qubits[j]]\n",
    "    else:\n",
    "        column_Xchecks = [X_pos_index_map[i + n_V, n_C] for i in range(n_C)]\n",
    "        columm_qubits = [q_pos_index_map[i, n_C] for i in range(n_V)]\n",
    "\n",
    "        H = np.zeros([len(column_Xchecks), len(columm_qubits)])\n",
    "\n",
    "        for i in range(len(column_Xchecks)):\n",
    "            for j in range(len(columm_qubits)):\n",
    "                H[i,j] = h[column_Xchecks[i], columm_qubits[j]]\n",
    "    return H\n",
    "\n",
    "def ColorProductCircuit(q_h, check_type):\n",
    "    assert check_type in ['X', 'Z'], f'check_type should be either X or Z'\n",
    "    n = q_h.shape[1]\n",
    "    n0 = np.sqrt(n/25)\n",
    "    n_C, n_V = int(3*n0), int(4*n0)\n",
    "    \n",
    "    q_pos_index_map = GetPosToQubitIndexMap(n_C, n_V)\n",
    "    Z_pos_index_map = GetPosToZCheckIndexMap(n_C, n_V)\n",
    "    X_pos_index_map = GetPosToXCheckIndexMap(n_C, n_V)\n",
    "    \n",
    "    c_h = ClassicalCheckFromQuantumCheck(q_h, check_type)\n",
    "    classical_coloration_scheduling = ColorationCircuit(c_h)\n",
    "    \n",
    "    scheduling = []\n",
    "    \n",
    "    if check_type == 'Z':\n",
    "        # add the vertical connections\n",
    "        for c in classical_coloration_scheduling:\n",
    "            v_c = {}\n",
    "            for c_index in list(c.keys()):\n",
    "                q_y = c_index + n_V\n",
    "                Z_y = c[c_index]\n",
    "                for q_x, Z_x in zip(range(n_C), range(n_C)):\n",
    "                    q_pos = q_y, q_x\n",
    "                    q_index = q_pos_index_map[q_pos]\n",
    "                    Z_pos = Z_y, Z_x\n",
    "                    Z_index = Z_pos_index_map[Z_pos]\n",
    "                    v_c[Z_index] = q_index\n",
    "            scheduling.append(v_c)\n",
    "\n",
    "            h_c = {}\n",
    "            for c_index in list(c.keys()):\n",
    "                Z_x = c_index \n",
    "                q_x = c[c_index] + n_C\n",
    "                for q_y, Z_y in zip(range(n_V), range(n_V)):\n",
    "                    q_pos = q_y, q_x\n",
    "                    q_index = q_pos_index_map[q_pos]\n",
    "                    Z_pos = Z_y, Z_x\n",
    "                    Z_index = Z_pos_index_map[Z_pos]\n",
    "                    h_c[Z_index] = q_index\n",
    "            scheduling.append(h_c)\n",
    "            \n",
    "    else:\n",
    "        for c in classical_coloration_scheduling:\n",
    "            v_c = {}\n",
    "            for c_index in list(c.keys()):\n",
    "                X_y = c_index + n_V\n",
    "                q_y = c[c_index]\n",
    "                for q_x, X_x in zip(n_C + np.arange(n_V), n_C + np.arange(n_V)):\n",
    "                    q_pos = q_y, q_x\n",
    "                    q_index = q_pos_index_map[q_pos]\n",
    "                    X_pos = X_y, X_x\n",
    "                    X_index = X_pos_index_map[X_pos]\n",
    "                    v_c[X_index] = q_index\n",
    "            scheduling.append(v_c)\n",
    "\n",
    "            h_c = {}\n",
    "            for c_index in list(c.keys()):\n",
    "                q_x = c_index \n",
    "                X_x = c[c_index] + n_C\n",
    "                for q_y, X_y in zip(n_V + np.arange(n_C), n_V + np.arange(n_C)):\n",
    "                    q_pos = q_y, q_x\n",
    "                    q_index = q_pos_index_map[q_pos]\n",
    "                    X_pos = X_y, X_x\n",
    "                    X_index = X_pos_index_map[X_pos]\n",
    "                    h_c[X_index] = q_index\n",
    "            scheduling.append(h_c)\n",
    "    return scheduling   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b630038-6625-4547-916d-f585097998f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sympy import *\n",
    "from sympy import Matrix, zeros\n",
    "from sympy import eye\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from sympy import symbols, Poly\n",
    "#import seaborn as sns\n",
    "#from sympy.polys.galoistools import gf_gcd, gf_div, gf_gcdex\n",
    "#from sympy.polys.domains import ZZ\n",
    "#from numpy.random import SeedSequence, default_rng\n",
    "#import multiprocessing\n",
    "####矩阵在二元域进行运算\n",
    "def mod2(matrix):\n",
    "    \"\"\"Reduce a matrix to modulo 2\"\"\"\n",
    "    return np.mod(matrix, 2)\n",
    "#矩阵进行行和列交换\n",
    "def generate_repetition_code_check_matrix(n):\n",
    "    # 校验矩阵的大小为 (n-1) x n\n",
    "    H = np.zeros((n-1, n), dtype=int)\n",
    "    \n",
    "    for i in range(n-1):\n",
    "        H[i, i] = 1\n",
    "        H[i, i+1] = 1\n",
    "    \n",
    "    return H\n",
    "def swap_columns(matrix, col1, col2):\n",
    "    matrix[:, [col1, col2]] = matrix[:, [col2, col1]]\n",
    "    return matrix\n",
    "def swap_rows(matrix, row1, row2):\n",
    "    matrix[[row1,row2],:] = matrix[[row2,row1],:]\n",
    "    return matrix\n",
    "#矩阵化成阶梯型\n",
    "def gf2_rref(matrix):\n",
    "    \"\"\"Compute the reduced row echelon form (RREF) of a matrix in GF(2)\"\"\"\n",
    "    matrix = mod2(matrix)\n",
    "    rows, cols = matrix.shape\n",
    "    row, col = 0, 0\n",
    "\n",
    "    while row < rows and col < cols:\n",
    "        if matrix[row, col] == 0:\n",
    "            for r in range(row + 1, rows):\n",
    "                if matrix[r, col] == 1:\n",
    "                    matrix[[row, r]] = matrix[[r, row]]\n",
    "                    break\n",
    "        if matrix[row, col] == 1:\n",
    "            for r in range(rows):\n",
    "                if r != row and matrix[r, col] == 1:\n",
    "                    matrix[r] = mod2(matrix[r] + matrix[row])\n",
    "            row += 1\n",
    "        col += 1\n",
    "    return matrix\n",
    "\n",
    "#矩阵化成(I P)\\pi 型\n",
    "def create_identity_at_top(matrix):\n",
    "    \"\"\"Ensure the first k rows and k columns form an identity matrix using column swaps\"\"\"\n",
    "   \n",
    "    matrix = gf2_rref(matrix)\n",
    "    rows, cols = matrix.shape\n",
    "    P = np.eye(cols)\n",
    "    \n",
    "    for i in range(rows):\n",
    "        if matrix[i, i] != 1:\n",
    "            for j in range(i + 1, cols):\n",
    "                if matrix[i, j] == 1:\n",
    "                    swap_columns(matrix, i, j)\n",
    "                    swap_rows(P,i, j)#交换矩阵\\pi\n",
    "                    break\n",
    "    return matrix,P\n",
    "#Calculate the kernel of the matrix (P^T I)based on (I P)\n",
    "\n",
    "def kernel_gf2(matrix):\n",
    "    \"\"\"Compute the kernel of a matrix in GF(2)\"\"\"\n",
    "    matrix_rref = gf2_rref(matrix)\n",
    "    rows, cols = matrix_rref.shape\n",
    "    pivot_cols = []\n",
    "\n",
    "    for r in range(rows):\n",
    "        for c in range(cols):\n",
    "            if matrix_rref[r, c] == 1:\n",
    "                pivot_cols.append(c)\n",
    "                break\n",
    "\n",
    "    free_vars = [c for c in range(cols) if c not in pivot_cols]\n",
    "    kernel_basis = []\n",
    "    #print(free_vars)\n",
    "    for free_var in free_vars:\n",
    "        basis_vector = np.zeros(cols, dtype=int)\n",
    "        basis_vector[free_var] = 1\n",
    "        for pivot_col in pivot_cols:\n",
    "            row = pivot_cols.index(pivot_col)\n",
    "            if matrix_rref[row, free_var] == 1:\n",
    "                basis_vector[pivot_col] = 1\n",
    "        kernel_basis.append(basis_vector)\n",
    "\n",
    "    return np.array(kernel_basis).T\n",
    "#circulant\n",
    "def polynomial_to_circulant(poly, l):\n",
    "    \n",
    "    x = symbols('x')\n",
    "\n",
    "   \n",
    "    if not isinstance(poly, Poly):\n",
    "        poly = Poly(poly, x,domain=ZZ)\n",
    "\n",
    "    \n",
    "    coeffs = poly.all_coeffs()\n",
    "    coeffs.reverse()\n",
    "    circulant_matrix = np.zeros((l, l), dtype=int)\n",
    "    for i in range(l):\n",
    "        a1 = np.pad( coeffs, (0, l - len( coeffs)), 'constant')\n",
    "        circulant_matrix[i] = row = np.roll(a1, i)\n",
    "\n",
    "    return circulant_matrix\n",
    "def create_identity_at_topH_X(matrix):\n",
    "    \"\"\"Ensure the first k rows and k columns form an identity matrix using column swaps\"\"\"\n",
    "   \n",
    "    matrix = gf2_rref(matrix)\n",
    "    rows, cols = matrix.shape\n",
    "    P = np.eye(cols)\n",
    "    \n",
    "    for i in range(rows):\n",
    "        if matrix[i, i] != 1:\n",
    "            for j in range(i + 1, cols):\n",
    "                if matrix[i, j] == 1:\n",
    "                    swap_columns(matrix, i, j)\n",
    "                    swap_rows(P,i, j)\n",
    "                    break\n",
    "    return matrix,P\n",
    "def gf2_rrefH_Z(matrix,r_X):\n",
    "    \"\"\"Compute the reduced row echelon form (RREF) of a matrix in GF(2)\"\"\"\n",
    "\n",
    "    matrix = mod2(matrix)\n",
    "    rows, cols = matrix.shape\n",
    "    row, col = 0, r_X\n",
    "\n",
    "    while row < rows and col < cols:\n",
    "        if matrix[row, col] == 0:\n",
    "            for r in range(row + 1, rows):\n",
    "                if matrix[r, col] == 1:\n",
    "                    matrix[[row, r]] = matrix[[r, row]]\n",
    "                    break\n",
    "        if matrix[row, col] == 1:\n",
    "            for r in range(rows):\n",
    "                if r != row and matrix[r, col] == 1:\n",
    "                    matrix[r] = mod2(matrix[r] + matrix[row])\n",
    "            row += 1\n",
    "        col += 1\n",
    "    return matrix\n",
    "def create_identity_at_topH_Z(matrix,r_X):\n",
    "    \"\"\"Ensure the first k rows and k columns form an identity matrix using column swaps\"\"\"\n",
    "    \n",
    "    matrix = gf2_rrefH_Z(matrix,r_X)\n",
    "    rows, cols = matrix.shape\n",
    "    P1 = np.eye(cols)\n",
    "    for i in range(rows):\n",
    "        if matrix[i, r_X] != 1:\n",
    "            for j in range(r_X , cols):\n",
    "                if matrix[i, j] == 1:\n",
    "                    swap_columns(matrix, r_X + i, j)\n",
    "                    swap_rows(P1,r_X+i, j)\n",
    "                    break\n",
    "    rows, cols = P1.shape\n",
    "    \n",
    "    return matrix,P1\n",
    "def CSS_code_Logical(H_X,H_Z):\n",
    "    r_X = H_X.shape[0]\n",
    "    r_Z = H_Z.shape[0]\n",
    "    n = H_X.shape[1]\n",
    "    H_X1,P = create_identity_at_topH_X(H_X)\n",
    "    \n",
    "    H_Z1 = H_Z @ P.T\n",
    "    H_Z1,P1 = create_identity_at_topH_Z(H_Z1,r_X)\n",
    "    \n",
    "    H_X1 = H_X1@P1.T\n",
    "    \n",
    "    k = n-r_Z-r_X\n",
    "    \n",
    "    I_k = np.eye(k)\n",
    "    A_2 = H_X1[:,-k:]\n",
    "    C_2 = H_Z1[:,-k:]\n",
    "\n",
    "    O_k_r_Z= np.zeros((k, r_Z), dtype=int)\n",
    "    O_k_r_X= np.zeros((k, r_X), dtype=int)\n",
    "    J_X = np.hstack((O_k_r_X,C_2.T, I_k)) \n",
    "    J_Z =  np.hstack((A_2.T,O_k_r_Z , I_k)) \n",
    "    I_s = np.hstack((np.zeros((k, n-k),dtype=int), I_k))\n",
    "\n",
    "    J_X = J_X@P1@P%2\n",
    "    J_Z = J_Z@P1@P%2\n",
    "    I_s = I_s@P1@P%2\n",
    "    return J_X,J_Z,I_s\n",
    "def Glue_code(J_Z_A,H_X):\n",
    "    non_zero_cols = [col_idx for col_idx in range(J_Z_A.shape[1]) if not all(row[col_idx] == 0 for row in J_Z_A)]#n_G\n",
    "    H_G1=H_X[:,non_zero_cols]\n",
    "    \n",
    "\n",
    "    non_zero_row = [row_idx for row_idx in range(H_G1.shape[0]) if not np.all(H_G1[row_idx] == 0)]\n",
    "    H_G=H_G1[non_zero_row,: ]#H_N\n",
    "    #生成S\n",
    "    num_rows = len(non_zero_cols)#r_N\n",
    "    num_cols = H_X.shape[1]\n",
    "    result_matrix = np.zeros((num_rows, num_cols), dtype=int)\n",
    "    for row_idx, col_idx in enumerate(non_zero_cols):\n",
    "        result_matrix[row_idx, col_idx] = 1\n",
    "    S_matrix = result_matrix\n",
    "    #生成T矩阵\n",
    "    num_cols = len(non_zero_row)#\n",
    "    num_rows = H_X.shape[0] #r_Z\n",
    "    T_matrix = np.zeros((num_rows, num_cols), dtype=int)\n",
    "    for col_idx, row_idx in enumerate(non_zero_row):\n",
    "        T_matrix[row_idx, col_idx] = 1    \n",
    "    \n",
    "    return H_G,T_matrix,S_matrix,non_zero_cols\n",
    "#生成重复码的check matrix\n",
    "\n",
    "\n",
    "def deformed_code(H_X,H_Z,J_Z,D):\n",
    "    J_Z = J_Z\n",
    "    H_X = H_X\n",
    "    H_Z = H_Z\n",
    "    H_G,T_matrix,S_matrix= Glue_code(J_Z,H_X)\n",
    "    H=generate_repetition_code_check_matrix(D)\n",
    "    H_X_M,H_Z_M=hypergraph_product_code(H_G, H.T)\n",
    "    vector1 = np.zeros(D-1, dtype=int)\n",
    "    vector3 = np.zeros(D, dtype=int)\n",
    "    vector3[0] = 1\n",
    "    vector2 = np.zeros((H_X.shape[0],H_G.shape[1]), dtype=int)\n",
    "    T_matrix = np.hstack((np.kron(vector1,vector2), np.kron(vector3, T_matrix)))%2\n",
    "    H_X1=np.hstack((H_X, T_matrix))\n",
    "    O_rGD=np.zeros((H_G.shape[0]*(D-1),H_X.shape[1]), dtype=int)\n",
    "    H_X_M=np.hstack((O_rGD, H_X_M))\n",
    "    H_X_deformed = np.vstack((H_X1,H_X_M))\n",
    "    #print(S_matrix.shape[0])\n",
    "    vector31=vector3.T\n",
    "    vector31 = vector3.reshape(-1, 1)\n",
    "    #print(vector31.shape[0])\n",
    "    S_matrix = np.kron(vector31,S_matrix)%2\n",
    "    #print(S_matrix.shape[0])\n",
    "    #print(H_Z_M.shape[0])\n",
    "    H_Z_M = np.hstack((S_matrix, H_Z_M ))\n",
    "    O_nGD=np.zeros((H_Z.shape[0],H_G.shape[1]*(D-1)+H_G.shape[0]*(D)), dtype=int)\n",
    "    H_Z1=np.hstack((H_Z, O_nGD))\n",
    "    H_Z_deformed = np.vstack((H_Z1,H_Z_M))\n",
    "    return H_X_deformed,H_Z_deformed,H_Z_M,H_X_M,H_Z1,H_X1\n",
    "def deformed_code_surface_code(H_X,H_Z,J_Z,D):\n",
    "    J_Z = J_Z\n",
    "    H_X = H_X\n",
    "    H_Z = H_Z\n",
    "    H_G,T_matrix,S_matrix= Glue_code(J_Z,H_X)\n",
    "    O1 = np.zeros((H_X.shape[0],H_X.shape[1]))\n",
    "    HX1 = np.hstack((H_X, O1))\n",
    "    J_Z1=np.hstack((J_Z, np.zeros((J_Z.shape[0],H_X.shape[1]))))\n",
    "    J_Z2=np.hstack((np.zeros((J_Z.shape[0],H_X.shape[1])),J_Z))\n",
    "    J_Z_def = np.vstack((J_Z1,J_Z2))\n",
    "    HX11 = np.hstack((HX1, T_matrix))\n",
    "    HX2 = np.hstack((np.zeros((H_X.shape[0],H_X.shape[1])),H_X))\n",
    "    HX22 = np.hstack((HX2, T_matrix))\n",
    "    hx = np.vstack((HX1,HX2))\n",
    "    J_Z_A= np.hstack((J_Z, J_Z))\n",
    "    J_Z_defM = np.hstack((J_Z_def,np.zeros((J_Z_def.shape[0],T_matrix.shape[1]))))\n",
    "    HZ1 = np.hstack((H_Z, np.zeros((H_Z.shape[0],H_Z.shape[1]))))\n",
    "    HZ2 = np.hstack((np.zeros((H_Z.shape[0],H_Z.shape[1])),H_Z))   \n",
    "    hz = np.vstack((HZ1,HZ2))\n",
    "    HZ11 = np.hstack((hz,np.zeros((hz.shape[0],H_G.shape[0]))))\n",
    "    H_X_deformed = np.vstack((HX11,HX22))\n",
    "    S_matrix = np.hstack((S_matrix,S_matrix))\n",
    "    S_matrix = np.hstack((S_matrix,H_G.T))\n",
    "    H_Z_deformed =  np.vstack((HZ11,S_matrix))\n",
    "    return H_X_deformed,H_Z_deformed,hx,hz,J_Z_def,J_Z_A,J_Z_defM\n",
    "def generate_matrix(HX, HXM,J_X,J_X_M,J_X_A,d):\n",
    "    # 创建一个零矩阵\n",
    "    m1,n1 = HX.shape\n",
    "    print(HX.shape)\n",
    "    m2,n2 = HXM.shape\n",
    "    print(HXM.shape)\n",
    "    rows = 2*m1+(d-1)*m2\n",
    "    cols = (d+1)*n2+d*m2\n",
    "    A = np.zeros((rows, cols), dtype=object)\n",
    "    B = np.zeros((J_X.shape[0], cols), dtype=object)\n",
    "    C = np.zeros((J_X_A.shape[0], cols), dtype=object)\n",
    "    # 填充矩阵\n",
    "    A[:m1, :n1] = HX\n",
    "    B[:, :n1] = J_X\n",
    "    C[:, :n1] = J_X_A    \n",
    "    A[:m1, n2:n2+m1] = np.eye(m1).astype(int)\n",
    "    C[:, n2+m1:n2+m2] = np.ones(m2-m1).astype(int)    \n",
    "    A[m1+(d-1)*m2:, -n1:] = HX\n",
    "    B[:, -n1:] = J_X\n",
    "    A[m1+(d-1)*m2:,(d-1)*(n2+m2)+n2:(d-1)*(n2+m2)+m1+n2 ] = np.eye(m1).astype(int)\n",
    "\n",
    "    for i in range(2, d + 1):\n",
    "        A[m1+(i-2)*m2:m1+(i-1)*m2, (i-2)*(n2+m2)+n2:(i-1)*(n2+m2)] =  np.eye(m2).astype(int)\n",
    "        A[m1+(i-2)*m2:m1+(i-1)*m2, (i-1)*(n2+m2):(i-1)*(n2+m2)+n2] = HXM\n",
    "        B[:, (i-1)*(n2+m2):(i-1)*(n2+m2)+n2]=J_X_M\n",
    "        A[m1+(i-2)*m2:m1+(i-1)*m2, (i-1)*(n2+m2)+n2:(i-1)*(n2+m2)+m2+n2] = np.eye(m2).astype(int)\n",
    "    \n",
    "    M = np.vstack((B,C))\n",
    "    \n",
    "    return A,M\n",
    "def hypergraph_product_code1(H1, H2):\n",
    "    # 获取矩阵的形状\n",
    "    m1, n1 = H1.shape\n",
    "    m2, n2 = H2.shape\n",
    "\n",
    "    # 构造单位矩阵\n",
    "    I1 = np.eye(n1, dtype=int)\n",
    "    I2 = np.eye(n2, dtype=int)\n",
    "    I3 = np.eye(m1, dtype=int)\n",
    "    I4 = np.eye(m2, dtype=int)\n",
    "    vectors = np.zeros(n2,dtype=int)\n",
    "    vectors[0]=1\n",
    "    # 构造 H_X\n",
    "    HZ = np.hstack((np.kron(I2,H1)%2, np.kron(H2.T,I3)%2))\n",
    "    LX = np.hstack((np.kron(vectors,np.ones(n1,dtype=int))%2, np.zeros(m2*m1,dtype=int)%2))\n",
    "    LX = np.atleast_2d(LX)    \n",
    "    # 构造 H_Z\n",
    "    HX = np.hstack((np.kron(H2,I1)%2, np.kron(I4,H1.T)%2))\n",
    "    \n",
    "    return HX, HZ,LX\n",
    "def hypergraph_product_code(H1, H2):\n",
    "    # 获取矩阵的形状\n",
    "    m1, n1 = H1.shape\n",
    "    m2, n2 = H2.shape\n",
    "    \n",
    "    # 构造单位矩阵\n",
    "    I1 = np.eye(n1, dtype=int)\n",
    "    I2 = np.eye(n2, dtype=int)\n",
    "    I3 = np.eye(m1, dtype=int)\n",
    "    I4 = np.eye(m2, dtype=int)\n",
    "    \n",
    "    # 构造 H_X\n",
    "    HX = np.hstack((np.kron(I2,H1)%2, np.kron(H2.T,I3)%2))\n",
    "    \n",
    "    # 构造 H_Z\n",
    "    HZ = np.hstack((np.kron(H2,I1)%2, np.kron(I4,H1.T)%2))\n",
    "    \n",
    "    return HX, HZ\n",
    "def extract_logical_qubit_positions(I_s):\n",
    "    \"\"\"\n",
    "    提取 I_s 中每行非零元素的列索引\n",
    "    :param I_s: 二进制矩阵，维度为 (k, n)\n",
    "    :return: 列表，每个元素是逻辑比特对应的物理比特位置列表\n",
    "    \"\"\"\n",
    "    logical_positions = []\n",
    "    for i in range(I_s.shape[0]):\n",
    "        non_zero = np.where(I_s[i] == 1)[0].tolist()\n",
    "        logical_positions.append(non_zero)\n",
    "    return logical_positions\n",
    "def first_nonzero_per_row(matrix):\n",
    "    \"\"\"\n",
    "    返回矩阵每一行第一个非零元素的列索引\n",
    "    输入: 二维列表或 NumPy 数组\n",
    "    输出: 列表，元素为各行的第一个非零列索引（全零行返回 -1）\n",
    "    \"\"\"\n",
    "    arr = np.asarray(matrix)\n",
    "    mask = (arr != 0) \n",
    "    \n",
    "    has_nonzero = np.any(mask, axis=1) \n",
    "    \n",
    "    # 对每行找到第一个 True 的位置，全零行设为 -1\n",
    "    indices = np.where(has_nonzero, np.argmax(mask, axis=1), -1)\n",
    "    return indices.tolist()\n",
    "def block_diagonal(*matrices):\n",
    "    for mat in matrices:\n",
    "        if not isinstance(mat, np.ndarray):\n",
    "            raise TypeError(\"所有输入必须是 NumPy 数组\")\n",
    "        if mat.ndim != 2:\n",
    "            raise ValueError(\"输入矩阵必须是二维的\")\n",
    "    \n",
    "    # 计算总维度\n",
    "    rows = sum(m.shape[0] for m in matrices)\n",
    "    cols = sum(m.shape[1] for m in matrices)\n",
    "    \n",
    "    # 初始化全零矩阵\n",
    "    block_matrix = np.zeros((rows, cols), dtype=matrices[0].dtype)\n",
    "    \n",
    "    # 定位指针\n",
    "    row_ptr, col_ptr = 0, 0\n",
    "    \n",
    "    # 填充矩阵\n",
    "    for mat in matrices:\n",
    "        r, c = mat.shape\n",
    "        block_matrix[row_ptr:row_ptr+r, col_ptr:col_ptr+c] = mat\n",
    "        row_ptr += r\n",
    "        col_ptr += c\n",
    "    \n",
    "    return block_matrix\n",
    "def deformed_code_magic(H_X_1,H_Z_1,J_Z_1,J_Z,I_s,H_X_2,H_Z_2,J_Z_2,D):\n",
    "    J_Z_1_0 = np.atleast_2d(J_Z_1[0])\n",
    "    J_Z_2 = np.atleast_2d(J_Z_2)\n",
    "    \n",
    "    # 生成对应的零数组，保持二维结构\n",
    "    zeros_2d = np.zeros((1, H_X_2.shape[1]), dtype=int)\n",
    "    \n",
    "    JZ1JZ1 = np.concatenate([J_Z_1_0, J_Z_2, zeros_2d], axis=1)\n",
    "    JZ2JZ2 = np.concatenate([np.atleast_2d(J_Z_1[1]), \n",
    "                            np.zeros((1, H_X_2.shape[1]), dtype=int), \n",
    "                            J_Z_2], axis=1)\n",
    "\n",
    "    H_G1,T1_matrix,S1_matrix,non_zero_cols1 = Glue_code(J_Z_1,H_X_1)\n",
    "    H_G2,T2_matrix,S2_matrix,non_zero_cols2 = Glue_code(J_Z_2,H_X_2)# surface code\n",
    "    S1_matrix1 = np.hstack((S1_matrix, np.zeros((S1_matrix.shape[0],H_X_2.shape[1]),dtype=int), np.zeros((S1_matrix.shape[0],H_X_2.shape[1]),dtype=int) ))\n",
    "    S2_matrix2 = np.hstack((np.zeros((S2_matrix.shape[0],H_X_1.shape[1]),dtype=int),S2_matrix,np.zeros((S2_matrix.shape[0],H_X_2.shape[1]),dtype=int)))\n",
    "    S3_matrix3 = np.hstack((np.zeros((S2_matrix.shape[0],H_X_1.shape[1]),dtype=int),np.zeros((S2_matrix.shape[0],H_X_2.shape[1]),dtype=int),S2_matrix ))\n",
    "    H_G1_T = np.hstack((H_G1.T,np.zeros((S1_matrix.shape[0],T2_matrix.shape[1]),dtype=int),np.zeros((S1_matrix.shape[0],T2_matrix.shape[1]),dtype=int)))\n",
    "    H_G2_T = np.hstack((np.zeros((S2_matrix.shape[0],T1_matrix.shape[1]),dtype=int),H_G2.T,np.zeros((S2_matrix.shape[0],T2_matrix.shape[1]),dtype=int)))\n",
    "    H_G3_T = np.hstack((np.zeros((S2_matrix.shape[0],T1_matrix.shape[1]),dtype=int),np.zeros((S2_matrix.shape[0],T2_matrix.shape[1]),dtype=int),H_G2.T))\n",
    "    vector1 = np.zeros(H_G1_T.shape[0],dtype=int)\n",
    "    T_matrix= block_diagonal(T1_matrix,T2_matrix,T2_matrix)\n",
    "    J_Z = block_diagonal(J_Z,J_Z_2,J_Z_2)\n",
    "    H_X = block_diagonal(H_X_1,H_X_2,H_X_2)\n",
    "    H_Z = block_diagonal(H_Z_1,H_Z_2,H_Z_2)\n",
    "    result = extract_logical_qubit_positions(I_s)\n",
    "    vector1[non_zero_cols1.index(result[-2][0])] = 1\n",
    "    vector2 = np.zeros(H_G1_T.shape[0],dtype=int)\n",
    "    vector2[non_zero_cols1.index(result[-1][0])] = 1  \n",
    "    vector3 = np.zeros(H_G2_T.shape[0],dtype=int)\n",
    "    vector3[0] = 1\n",
    "    vector1 = vector1.reshape(-1, 1)\n",
    "    vector2 = vector2.reshape(-1, 1)\n",
    "    vector3 = vector3.reshape(-1, 1)    \n",
    "    H_G1_T = np.hstack((H_G1_T,vector1,vector2))\n",
    "    \n",
    "    H_G2_T = np.hstack((H_G2_T,vector3,np.zeros((H_G2_T.shape[0]),dtype=int).reshape(-1, 1)))\n",
    "    H_G3_T = np.hstack((H_G3_T,np.zeros((H_G2_T.shape[0]),dtype=int).reshape(-1, 1),vector3))\n",
    "    \n",
    "    H_G = np.vstack((H_G1_T,H_G2_T,H_G3_T)).T\n",
    "    S_matrix = np.vstack((S1_matrix1,S2_matrix2,S3_matrix3))\n",
    "    JZ1JZ1 = np.kron(np.ones(D,dtype=int),JZ1JZ1@S_matrix.T ).astype(int)\n",
    "    JZ2JZ2 = np.kron(np.ones(D,dtype=int),JZ2JZ2@S_matrix.T ).astype(int)   \n",
    "    H=generate_repetition_code_check_matrix(D)\n",
    "\n",
    "    anciall = np.zeros((H_X.shape[0],2),dtype=int)\n",
    "    T_matrix = np.hstack((T_matrix,anciall))%2\n",
    "    H_X_M,H_Z_M=hypergraph_product_code(H_G, H.T)\n",
    "\n",
    "    vector1 = np.zeros(D-1, dtype=int)\n",
    "    vector3 = np.zeros(D, dtype=int)\n",
    "    vector3[0] = 1\n",
    "    vector2 = np.zeros((H_X.shape[0],H_G.shape[1]), dtype=int)\n",
    "    T_matrix = np.hstack((np.kron(vector1,vector2), np.kron(vector3, T_matrix)))%2\n",
    "    \n",
    "    H_X1=np.hstack((H_X, T_matrix))\n",
    "    O_rGD=np.zeros((H_G.shape[0]*(D-1),H_X.shape[1]), dtype=int)\n",
    "    H_X_M=np.hstack((O_rGD, H_X_M))\n",
    "    H_X_deformed = np.vstack((H_X1,H_X_M))\n",
    "    #print(S_matrix.shape[0])\n",
    "    vector31=vector3.T\n",
    "    vector31 = vector3.reshape(-1, 1)\n",
    "\n",
    "    S_matrix = np.kron(vector31,S_matrix)%2\n",
    "    #print(S_matrix.shape[0])\n",
    "    #print(H_Z_M.shape[0])\n",
    "    H_Z_M = np.hstack((S_matrix, H_Z_M ))\n",
    "    O_nGD=np.zeros((H_Z.shape[0],H_G.shape[1]*(D-1)+H_G.shape[0]*(D)), dtype=int)\n",
    "    H_Z1=np.hstack((H_Z, O_nGD))\n",
    "    H_Z_deformed = np.vstack((H_Z1,H_Z_M))\n",
    " \n",
    "    return H_X_deformed,H_Z_deformed,JZ1JZ1,JZ2JZ2,J_Z,H_X,H_Z\n",
    "def validate_check_matrix(check_matrix):\n",
    "    # 如果是稀疏矩阵，先转换为密集矩阵\n",
    "    dense_matrix = check_matrix.toarray() if isinstance(check_matrix, csc_matrix) else check_matrix\n",
    "    for col_idx in range(dense_matrix.shape[1]):\n",
    "        if np.sum(dense_matrix[:, col_idx]) > 2:\n",
    "            print(f\"第 {col_idx} 列有超过两个1.\")\n",
    "            # 根据需要处理错误，比如抛出异常\n",
    "            raise ValueError(f\"第 {col_idx} 列包含超过两个1.\")\n",
    "    return check_matrix  # 如果没有问题，返回原矩阵\n",
    "from scipy import sparse\n",
    "from ldpc.codes import rep_code\n",
    "import pymatching \n",
    "from scipy.sparse import csc_matrix\n",
    "import numpy as np\n",
    "from bposd.hgp import hgp\n",
    "def remove_zero_rows(matrix):\n",
    "    \"\"\"\n",
    "    删除矩阵中所有全零行\n",
    "    输入: 二维列表或 NumPy 数组\n",
    "    输出: 删除全零行后的 NumPy 数组（保留原始顺序）\n",
    "    \"\"\"\n",
    "    arr = np.array(matrix)  # 转换为 NumPy 数组\n",
    "    non_zero_mask = np.any(arr != 0, axis=1)  # 标记非零行\n",
    "    return arr[non_zero_mask]\n",
    "\n",
    "def cyclic_shift(l):\n",
    "    return np.roll(np.eye(l, dtype=int), shift=1, axis=1)\n",
    "\n",
    "def construct_ldpc(ell, m, code):\n",
    "    # 生成基础矩阵\n",
    "    x = np.kron(cyclic_shift(ell), np.eye(m, dtype=int))\n",
    "    y = np.kron(np.eye(ell, dtype=int), cyclic_shift(m))\n",
    "    \n",
    "    # 构造A和B矩阵\n",
    "    A = (np.linalg.matrix_power(x, code[0]) + np.linalg.matrix_power(y, code[1]) + np.linalg.matrix_power(y, code[2])) % 2\n",
    "    B = (np.linalg.matrix_power(y, code[3]) + np.linalg.matrix_power(x, code[4]) + np.linalg.matrix_power(x, code[5])) % 2\n",
    "    \n",
    "    # 校验正交性\n",
    "    assert np.all((A @ B + B @ A) % 2 == 0), \"Orthogonality failed!\"\n",
    "    \n",
    "    # 构建Hx和Hz\n",
    "    Hx = np.hstack([A, B]).astype(int)\n",
    "    Hz = np.hstack([B.T, A.T]).astype(int)\n",
    "    return Hx, Hz\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b95f089-5830-44c0-8d17-73157e3bf0fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import copy\n",
    "import time\n",
    "from typing import Union\n",
    "import collections\n",
    "\n",
    "out_count_observable_error_combos: Union[None, collections.Counter]  # 移除 [str]\n",
    "\n",
    "import bposd.hgp\n",
    "\n",
    "from bposd.hgp import hgp\n",
    "import multiprocessing as mp\n",
    "from ldpc.codes import ring_code\n",
    "import stim\n",
    "import re\n",
    "import sys\n",
    "sys.path.append(\"./src/\")\n",
    "import pymatching\n",
    "import sinter\n",
    "from typing import *\n",
    "import re\n",
    "def QECCircuit_OneStage(H_Z,H_X,J_X_1,J_X,I_s,hz,hx,lx, num_rep, circuit_error_params, p,circuit_type,D):\n",
    "        \n",
    "        # give out \\bar{H_X} and \\bar{H_Z} based on (H_X，H_Z)\n",
    "        H_Z_deformed,H_X_deformed,JX1JX1,JX2JX2,J_X,hz,hx = deformed_code_magic(H_Z,H_X,J_X_1,J_X,I_s,hz,hx,lx,D) \n",
    "        M = H_Z_deformed@H_X_deformed.T%2 \n",
    "        print(remove_zero_rows(M))# Verify whether the matrices commute.\n",
    "        if circuit_type == 'coloration':\n",
    "           scheduling_X = ColorationCircuit(hx)\n",
    "           scheduling_Z = ColorationCircuit(hz)\n",
    "############################################################################################### Initialization\n",
    "        H_X = hx\n",
    "        H_Z = hz\n",
    "        data_indices = list(np.arange(0, np.shape(H_X)[1]))\n",
    "        data_indicesancilla = list(np.arange(np.shape(H_X)[1], np.shape(H_X_deformed)[1]))\n",
    "        n = len(data_indices) + len(data_indicesancilla)\n",
    "        n_Z_ancilla, n_X_ancilla = np.shape(H_Z)[0], np.shape(H_X)[0]\n",
    "        n_Z_ancillaM, n_X_ancillaM =  np.shape(H_Z_deformed)[0]- np.shape(H_Z)[0], np.shape(H_X_deformed)[0]- np.shape(H_X)[0]\n",
    "\n",
    "        Z_ancilla_indices = list(np.arange(n, n + n_Z_ancilla))\n",
    "        Z_ancilla_indicesM = list(np.arange(n + n_Z_ancilla ,\n",
    "                                        n + n_Z_ancilla  + n_Z_ancillaM))\n",
    "        X_ancilla_indices = list(np.arange(n + n_Z_ancilla+ n_Z_ancillaM, n + n_Z_ancilla+ n_Z_ancillaM + n_X_ancilla))\n",
    "        X_ancilla_indicesM = list(np.arange(n + n_Z_ancilla + n_Z_ancillaM + n_X_ancilla,\n",
    "                                        n + n_Z_ancilla+ n_Z_ancillaM + n_X_ancilla + n_X_ancillaM))\n",
    "        circuit_init = stim.Circuit()\n",
    "        circuit_init.append(\"RX\", data_indices)\n",
    "        circuit_init.append(\"R\", X_ancilla_indices )\n",
    "        circuit_init.append(\"R\",  Z_ancilla_indices)\n",
    "        circuit_init.append(\"R\", data_indicesancilla)\n",
    "        \n",
    "        circuit_init.append(\"R\", X_ancilla_indicesM )\n",
    "        circuit_init.append(\"R\",  Z_ancilla_indicesM)\n",
    "        circuit_stab_meas = stim.Circuit()\n",
    "        circuit_stab_meas.append(\"H\", X_ancilla_indices)\n",
    "        \n",
    "        circuit_stab_meas.append(\"TICK\")\n",
    "        \n",
    "        for time_step in range(len(scheduling_X)):\n",
    "            for j in scheduling_X[time_step]:\n",
    "#                 \n",
    "                X_ancilla_index = X_ancilla_indices[j]\n",
    "                data_index = scheduling_X[time_step][j]\n",
    "                circuit_stab_meas.append(\"CX\", [X_ancilla_index, data_index])\n",
    "            circuit_stab_meas.append(\"TICK\")\n",
    "        circuit_stab_meas.append(\"TICK\")\n",
    "        \n",
    "        for time_step in range(len(scheduling_Z)):\n",
    "            for j in scheduling_Z[time_step]:\n",
    "#                 supported_data_qubits = list(np.where(hz[Z_ancilla_index - n,:] == 1)[0])\n",
    "                Z_ancilla_index = Z_ancilla_indices[j]\n",
    "                data_index = scheduling_Z[time_step][j]\n",
    "                # data_index = supported_data_qubits[i]\n",
    "                circuit_stab_meas.append(\"CX\", [data_index, Z_ancilla_index])\n",
    "            circuit_stab_meas.append(\"TICK\")\n",
    "        circuit_stab_meas.append(\"TICK\")\n",
    "        circuit_stab_meas.append(\"H\", X_ancilla_indices)\n",
    "        circuit_stab_meas.append(\"MR\", Z_ancilla_indices )\n",
    "        circuit_stab_meas.append(\"MR\", X_ancilla_indices)\n",
    "\n",
    "\n",
    "################################################################################## d_T parity check measurement of both the memory code and surface code\n",
    "        error_params = {\"p_i\": circuit_error_params[\"p_i\"]*p, \"p_state_p\": circuit_error_params[\"p_state_p\"]*p, \n",
    "        \"p_m\": circuit_error_params[\"p_m\"]*p, \"p_CX\":circuit_error_params[\"p_CX\"]*p, \n",
    "        \"p_idling_gate\": circuit_error_params[\"p_idling_gate\"]*p,\"p_H\" : circuit_error_params[\"p_H\"]*p,\"p_deg\" : circuit_error_params[\"p_deg\"]*p}\n",
    "        circuit_stab_meas_Hx1 = stim.Circuit()\n",
    "\n",
    "        circuit_stab_meas_Hx1.append(\"H\", X_ancilla_indices)\n",
    "        circuit_stab_meas_Hx1.append(\"DEPOLARIZE1\", X_ancilla_indices, (error_params['p_state_p']))\n",
    "    #circuit_stab_meas_Hx1.append(\"DEPOLARIZE1\", X_ancilla_indices, (error_params['p_H'])) # Add the state preparation error # Add the idling errors on the data qubits during the preparation for X ancillas\n",
    "        circuit_stab_meas_Hx1.append(\"TICK\")\n",
    "        circuit_stab_meas_Hx1.append(\"DEPOLARIZE1\", data_indices , (error_params['p_idling_gate'])) \n",
    "    # Apply CX gates for the X stabilizers\n",
    "        for time_step in range(len(scheduling_X)):\n",
    "        # add idling errors for all the qubits during the ancilla shuffling\n",
    "            idling_qubits = data_indices + X_ancilla_indices\n",
    "            idling_data_indices = list(copy.deepcopy(data_indices))\n",
    "        #circuit_stab_meas_Hx1.append(\"DEPOLARIZE1\", idling_qubits, (error_params['p_idling_gate'])) \n",
    "            for j in scheduling_X[time_step]:\n",
    "    #                 supported_data_qubits = list(np.where(hx[X_ancilla_index - n - n_Z_ancilla,:] == 1)[0])\n",
    "                X_ancilla_index = X_ancilla_indices[j]\n",
    "                data_index = scheduling_X[time_step][j]\n",
    "            # data_index = supported_data_qubits[i]\n",
    "                circuit_stab_meas_Hx1.append(\"CX\", [X_ancilla_index, data_index])\n",
    "                if data_index in idling_data_indices:\n",
    "                     idling_data_indices.pop(idling_data_indices.index(data_index))\n",
    "            circuit_stab_meas_Hx1.append(\"DEPOLARIZE1\", idling_data_indices, (error_params['p_idling_gate'])) # idling errors for qubits that are not being checked\n",
    "            circuit_stab_meas_Hx1.append(\"TICK\")\n",
    "\n",
    "    # meausure the Z ancillas\n",
    "        circuit_stab_meas_Hx1.append(\"DEPOLARIZE1\", Z_ancilla_indices, (error_params['p_state_p'])) # Add the state preparation error\n",
    "    # circuit_stab_meas_Hx1.append(\"DEPOLARIZE1\", data_indices, (error_params['p_i'])) # Add the idling errors on the data qubits during the preparation for Z ancillas\n",
    "    \n",
    "        circuit_stab_meas_Hx1.append(\"DEPOLARIZE1\",  data_indices , (error_params['p_idling_gate']))\n",
    "        circuit_stab_meas_Hx1.append(\"TICK\")\n",
    "    # Appy CX gates for the Z stabilziers\n",
    "        for time_step in range(len(scheduling_Z)):\n",
    "              idling_qubits = data_indices + Z_ancilla_indices\n",
    "              idling_data_indices = list(copy.deepcopy(data_indices))\n",
    "        #circuit_stab_meas_Hx1.append(\"DEPOLARIZE1\", idling_qubits, (error_params['p_idling_gate']))\n",
    "              for j in scheduling_Z[time_step]:\n",
    "    #                 supported_data_qubits = list(np.where(hz[Z_ancilla_index - n,:] == 1)[0])\n",
    "                  Z_ancilla_index = Z_ancilla_indices[j]\n",
    "                  data_index = scheduling_Z[time_step][j]\n",
    "            # data_index = supported_data_qubits[i]\n",
    "                  circuit_stab_meas_Hx1.append(\"CX\", [data_index, Z_ancilla_index])\n",
    "                  if data_index in idling_data_indices:\n",
    "                         idling_data_indices.pop(idling_data_indices.index(data_index))\n",
    "              circuit_stab_meas_Hx1.append(\"DEPOLARIZE1\", idling_data_indices, (error_params['p_idling_gate'])) # idling errors for qubits that are not being checked\n",
    "              circuit_stab_meas_Hx1.append(\"TICK\")\n",
    "\n",
    "    # Measure the ancillas\n",
    "        \n",
    "        circuit_stab_meas_Hx1.append(\"H\", X_ancilla_indices)\n",
    "        circuit_stab_meas_Hx1.append(\"TICK\")\n",
    "        circuit_stab_meas_Hx1.append(\"DEPOLARIZE1\",  data_indices , (error_params['p_idling_gate']))\n",
    "\n",
    "        circuit_stab_meas_Hx1.append(\"DEPOLARIZE1\",  Z_ancilla_indices +X_ancilla_indices, (error_params['p_m'])) # Add the measurement error\n",
    "        circuit_stab_meas_Hx1.append(\"TICK\")\n",
    "        circuit_stab_meas_Hx1.append(\"MR\", Z_ancilla_indices + X_ancilla_indices)\n",
    "        circuit_stab_meas_Hx1.append(\"SHIFT_COORDS\", [], (1))\n",
    "        for i in range(len(X_ancilla_indices)):\n",
    "                 circuit_stab_meas_Hx1.append(\"DETECTOR\", [stim.target_rec(- len(X_ancilla_indices) + i)], (0))\n",
    "        circuit_stab_meas_Hx1.append(\"TICK\")\n",
    "        circuit_stab_meas_Hx2 = stim.Circuit()\n",
    "    \n",
    "        circuit_stab_meas_Hx2.append(\"H\", X_ancilla_indices)\n",
    "        circuit_stab_meas_Hx2.append(\"DEPOLARIZE1\", X_ancilla_indices, (error_params['p_state_p'])) \n",
    "    #circuit_stab_meas_Hx2.append(\"DEPOLARIZE1\", X_ancilla_indices, (error_params['p_H'])) # Add the state preparation error\n",
    "    #ircuit_stab_meas_rep2.append(\"DEPOLARIZE1\", data_indices, (error_params['p_i'])) # Add the idling errors on the data qubits during the preparation for X ancillas\n",
    "        circuit_stab_meas_Hx2.append(\"TICK\")\n",
    "        circuit_stab_meas_Hx2.append(\"DEPOLARIZE1\", data_indices , (error_params['p_idling_gate']))\n",
    "    # Apply CX gates for the X stabilizers\n",
    "        for time_step in range(len(scheduling_X)):\n",
    "                     idling_qubits = data_indices + X_ancilla_indices\n",
    "        #circuit_stab_meas_Hx2.append(\"DEPOLARIZE1\", idling_qubits, (error_params['p_idling_gate']))\n",
    "                     idling_data_indices = list(copy.deepcopy(data_indices))\n",
    "                     for j in scheduling_X[time_step]:\n",
    "    #                 supported_data_qubits = list(np.where(hx[X_ancilla_index - n - n_Z_ancilla,:] == 1)[0])\n",
    "                           X_ancilla_index = X_ancilla_indices[j]\n",
    "                           data_index = scheduling_X[time_step][j]\n",
    "            # data_index = supported_data_qubits[i]\n",
    "                           circuit_stab_meas_Hx2.append(\"CX\", [X_ancilla_index, data_index])\n",
    "                           if data_index in idling_data_indices:\n",
    "                                  idling_data_indices.pop(idling_data_indices.index(data_index))\n",
    "                     circuit_stab_meas_Hx2.append(\"DEPOLARIZE1\", idling_data_indices, (error_params['p_idling_gate'])) # idling errors for qubits that are not being checked\n",
    "                     circuit_stab_meas_Hx2.append(\"TICK\")\n",
    "        circuit_stab_meas_Hx2.append(\"DEPOLARIZE1\", Z_ancilla_indices, (error_params['p_state_p'])) # Add the state preparation error\n",
    "        circuit_stab_meas_Hx2.append(\"DEPOLARIZE1\", data_indices, (error_params['p_idling_gate'])) # Add the idling errors on the data qubits during the preparation for Z ancillas\n",
    "        circuit_stab_meas_Hx2.append(\"TICK\")\n",
    "        for time_step in range(len(scheduling_Z)):\n",
    "                  idling_qubits = data_indices + Z_ancilla_indices\n",
    "        #circuit_stab_meas_Hx2.append(\"DEPOLARIZE1\", idling_qubits, (error_params['p_idling_gate']))\n",
    "                  idling_data_indices = list(copy.deepcopy(data_indices))\n",
    "                  for j in scheduling_Z[time_step]:\n",
    "    #                 supported_data_qubits = list(np.where(hz[Z_ancilla_index - n,:] == 1)[0])\n",
    "                       Z_ancilla_index = Z_ancilla_indices[j]\n",
    "                       data_index = scheduling_Z[time_step][j]\n",
    "            # data_index = supported_data_qubits[i]\n",
    "                       circuit_stab_meas_Hx2.append(\"CX\", [data_index, Z_ancilla_index])\n",
    "                       if data_index in idling_data_indices:\n",
    "                                 idling_data_indices.pop(idling_data_indices.index(data_index))\n",
    "                  circuit_stab_meas_Hx2.append(\"DEPOLARIZE1\", idling_data_indices, (error_params['p_idling_gate'])) # idling errors for qubits that are not being checked\n",
    "                  circuit_stab_meas_Hx2.append(\"TICK\")        \n",
    "    # Measure the ancillas\n",
    "        circuit_stab_meas_Hx2.append(\"H\", X_ancilla_indices)\n",
    "        circuit_stab_meas_Hx2.append(\"TICK\")\n",
    "        circuit_stab_meas_Hx2.append(\"DEPOLARIZE1\", data_indices , (error_params['p_idling_gate'])) \n",
    "    #circuit_stab_meas_Hx2.append(\"DEPOLARIZE1\",  X_ancilla_indices, (error_params['p_H']))\n",
    "        circuit_stab_meas_Hx2.append(\"DEPOLARIZE1\",  Z_ancilla_indices +X_ancilla_indices, (error_params['p_m']))# Add the measurement error\n",
    "        circuit_stab_meas_Hx2.append(\"TICK\")\n",
    "        circuit_stab_meas_Hx2.append(\"MR\", Z_ancilla_indices + X_ancilla_indices)\n",
    "    #circuit_stab_meas_Hx2.append(\"SHIFT_COORDS\", [], (1))\n",
    "        for i in range(len(X_ancilla_indices)):\n",
    "            circuit_stab_meas_Hx2.append(\"DETECTOR\", [stim.target_rec(- len(X_ancilla_indices) + i), \n",
    "                                        stim.target_rec(- len(X_ancilla_indices) + i - len(Z_ancilla_indices) - len(X_ancilla_indices))], (0))\n",
    "        circuit_stab_meas_Hx2.append(\"TICK\")\n",
    "\n",
    "\n",
    "        circuit_stab_meas_repHxHx = circuit_stab_meas_Hx1 + (num_rep - 1)*circuit_stab_meas_Hx2\n",
    "######################################################################################################## d_T parity check measurement of  the deformed code\n",
    "        if circuit_type == 'coloration':\n",
    "            scheduling_X_deform = ColorationCircuit(H_X_deformed)\n",
    "            scheduling_Z_deform = ColorationCircuit(H_Z_deformed)\n",
    "        circuit_stab_meas_rep1 = stim.Circuit()\n",
    "#         circuit_stab_meas_rep1.append(\"DEPOLARIZE1\", data_indices, (pz)) # for debug\n",
    "        # measurement the X ancillas\n",
    "        # # Initialize the X ancillas to the + state\n",
    "        #circuit_stab_meas_rep1.append(\"DEPOLARIZE1\", data_indicesancilla , (error_params['p_deg'])) \n",
    "        circuit_stab_meas_rep1.append(\"DEPOLARIZE1\", data_indicesancilla, (error_params['p_state_p']))\n",
    "        circuit_stab_meas_rep1.append(\"TICK\")\n",
    "        circuit_stab_meas_rep1.append(\"H\", X_ancilla_indices+X_ancilla_indicesM)\n",
    "        circuit_stab_meas_rep1.append(\"DEPOLARIZE1\", X_ancilla_indices+X_ancilla_indicesM, (error_params['p_state_p']))\n",
    "        \n",
    "        circuit_stab_meas_rep1.append(\"TICK\") # Add the state preparation error\n",
    "        circuit_stab_meas_rep1.append(\"DEPOLARIZE1\", data_indices, (error_params['p_deg'])) # Add the idling errors on the data qubits during the preparation for X ancillas\n",
    "        circuit_stab_meas_rep1.append(\"TICK\")\n",
    "        # Apply CX gates for the X stabilizers\n",
    "        #circuit_stab_meas_rep1.append(\"DEPOLARIZE1\", data_indices + data_indicesancilla , (error_params['p_idling_gate']))#+ X_ancilla_indices+X_ancilla_indicesM\n",
    "        for time_step in range(len(scheduling_X_deform)):\n",
    "            # add idling errors for all the qubits during the ancilla shuffling\n",
    "            idling_qubits = data_indices + data_indicesancilla + X_ancilla_indices+X_ancilla_indicesM\n",
    "            idling_data_indices = list(copy.deepcopy(data_indices+data_indicesancilla))\n",
    "            #circuit_stab_meas_rep1.append(\"DEPOLARIZE1\", idling_qubits, (error_params['p_idling_gate'])) \n",
    "            for j in scheduling_X_deform[time_step]:\n",
    "#               \n",
    "                X_ancilla_index = (X_ancilla_indices+X_ancilla_indicesM)[j]\n",
    "                data_index = scheduling_X_deform[time_step][j]\n",
    "                \n",
    "                circuit_stab_meas_rep1.append(\"CX\", [X_ancilla_index, data_index])\n",
    "                if data_index in idling_data_indices:\n",
    "                    idling_data_indices.pop(idling_data_indices.index(data_index))\n",
    "            circuit_stab_meas_rep1.append(\"DEPOLARIZE1\", idling_data_indices, (error_params['p_deg'])) # idling errors for qubits that are not being checked\n",
    "            circuit_stab_meas_rep1.append(\"TICK\")\n",
    "        circuit_stab_meas_rep1.append(\"DEPOLARIZE1\", data_indices+ data_indicesancilla , (error_params['p_deg']))#idling errors for qubits that are not being Measurement\n",
    "        circuit_stab_meas_rep1.append(\"DEPOLARIZE1\", Z_ancilla_indices+Z_ancilla_indicesM, (error_params['p_state_p'])) # Add the state preparation error\n",
    "        circuit_stab_meas_rep1.append(\"TICK\")\n",
    "        #circuit_stab_meas_rep1.append(\"DEPOLARIZE1\", data_indices+ data_indicesancilla + Z_ancilla_indices+Z_ancilla_indicesM, (error_params['p_deg']))\n",
    "        for time_step in range(len(scheduling_Z_deform)):\n",
    "            idling_qubits = data_indices+ data_indicesancilla + Z_ancilla_indices+Z_ancilla_indicesM\n",
    "            idling_data_indices = list(copy.deepcopy(data_indices+data_indicesancilla))\n",
    "            #circuit_stab_meas_rep1.append(\"DEPOLARIZE1\", idling_qubits, (error_params['p_idling_gate']))\n",
    "            for j in scheduling_Z_deform[time_step]:\n",
    "#                 \n",
    "                Z_ancilla_index = (Z_ancilla_indices+Z_ancilla_indicesM)[j]\n",
    "                data_index = scheduling_Z_deform[time_step][j]\n",
    "                \n",
    "                circuit_stab_meas_rep1.append(\"CX\", [data_index, Z_ancilla_index])\n",
    "                if data_index in idling_data_indices:\n",
    "                    idling_data_indices.pop(idling_data_indices.index(data_index))\n",
    "            circuit_stab_meas_rep1.append(\"DEPOLARIZE1\", idling_data_indices, (error_params['p_deg'])) # idling errors for qubits that are not being checked\n",
    "            circuit_stab_meas_rep1.append(\"TICK\")\n",
    "        circuit_stab_meas_rep1.append(\"DEPOLARIZE1\", data_indices+data_indicesancilla, (error_params['p_deg']))\n",
    "        # Measure the ancillas\n",
    "        circuit_stab_meas_rep1.append(\"H\", X_ancilla_indices+ X_ancilla_indicesM)\n",
    "        circuit_stab_meas_rep1.append(\"TICK\")\n",
    "        circuit_stab_meas_rep1.append(\"DEPOLARIZE1\", X_ancilla_indices+ X_ancilla_indicesM+Z_ancilla_indices+Z_ancilla_indicesM , (error_params['p_m']))\n",
    "\n",
    "        circuit_stab_meas_rep1.append(\"TICK\")\n",
    "        #circuit_stab_meas_rep1.append(\"DEPOLARIZE1\",  X_ancilla_indices+ X_ancilla_indicesM, (3/2*error_params['p_m'])) # Add the measurement error\n",
    "        #circuit_final_mea.append(\"DEPOLARIZE1\", data_indices, (error_params['p_i'])) # Add the idling errors on the data qubits during the measurement of X ancillas\n",
    "        circuit_stab_meas_rep1.append(\"MR\", Z_ancilla_indices+Z_ancilla_indicesM )\n",
    "        circuit_stab_meas_rep1.append(\"MR\", X_ancilla_indices+X_ancilla_indicesM)\n",
    "        #circuit_stab_meas_rep1.append(\"RX\", X_ancilla_indices+X_ancilla_indicesM)\n",
    "        circuit_stab_meas_rep1.append(\"TICK\")\n",
    "        #circuit_stab_meas_rep1.append(\"SHIFT_COORDS\", [], (1))\n",
    "        for i in range(len(X_ancilla_indices)):\n",
    "            circuit_stab_meas_rep1.append(\"DETECTOR\", [stim.target_rec(- len(X_ancilla_indices)-len(X_ancilla_indicesM) + i),\n",
    "                                                       stim.target_rec(- len(X_ancilla_indices)-len(Z_ancilla_indices)-len(Z_ancilla_indicesM)-len(X_ancilla_indices)-len(X_ancilla_indicesM) + i)], (0))\n",
    "\n",
    "        logical_X_qubit_indicesm1 = list(np.where(JX1JX1[0,:] == 1)[0])\n",
    "        circuit_stab_meas_rep1.append(\"OBSERVABLE_INCLUDE\", \n",
    "                               [stim.target_rec(-len(X_ancilla_indicesM) + data_index1)for data_index1 in logical_X_qubit_indicesm1],\n",
    "                               (0))\n",
    "        logical_X_qubit_indicesm2 = list(np.where(JX2JX2[0,:] == 1)[0])\n",
    "        circuit_stab_meas_rep1.append(\"OBSERVABLE_INCLUDE\", \n",
    "                               [stim.target_rec(-len(X_ancilla_indicesM) + data_index1)for data_index1 in logical_X_qubit_indicesm2],\n",
    "                               (1))    \n",
    "        circuit_stab_meas_rep1.append(\"TICK\")\n",
    "        # rep with difference detectors\n",
    "        circuit_stab_meas_rep2 = stim.Circuit()\n",
    "        #circuit_stab_meas_rep2.append(\"DEPOLARIZE1\", data_indices+data_indicesancilla , (error_params['p_m']))\n",
    "        # measurement the X ancillas\n",
    "        # # Initialize the X ancillas to the + state\n",
    "#         circuit_stab_meas_rep2.append(\"DEPOLARIZE1\", data_indices, (pz)) # for debug\n",
    "        #circuit_stab_meas_rep2.append(\"DEPOLARIZE1\", data_indices + data_indicesancilla, (error_params['p_deg']))\n",
    "        circuit_stab_meas_rep2.append(\"DEPOLARIZE1\", X_ancilla_indices+X_ancilla_indicesM, (error_params['p_state_p']))\n",
    "        circuit_stab_meas_rep2.append(\"TICK\")# Add the state preparation error\n",
    "        circuit_stab_meas_rep2.append(\"H\", X_ancilla_indices+X_ancilla_indicesM)\n",
    "        circuit_stab_meas_rep2.append(\"DEPOLARIZE1\", data_indices + data_indicesancilla, (error_params['p_deg'])) \n",
    "        # circuit_final_mea.append(\"DEPOLARIZE1\", data_indices, (error_params['p_i'])) # Add the idling errors on the data qubits during the preparation for X ancillas\n",
    "        circuit_stab_meas_rep2.append(\"TICK\")\n",
    "        #circuit_stab_meas_rep2.append(\"DEPOLARIZE1\", data_indices + data_indicesancilla + X_ancilla_indices+X_ancilla_indicesM, (error_params['p_idling_gate']))\n",
    "        # Apply CX gates for the X stabilizers\n",
    "        for time_step in range(len(scheduling_X_deform)):\n",
    "            # add idling errors for all the qubits during the ancilla shuffling\n",
    "            idling_qubits = data_indices + data_indicesancilla + X_ancilla_indices+X_ancilla_indicesM\n",
    "            idling_data_indices = list(copy.deepcopy(data_indices+data_indicesancilla))\n",
    "            #circuit_stab_meas_rep2.append(\"DEPOLARIZE1\", idling_qubits, (error_params['p_idling_gate'])) \n",
    "            for j in scheduling_X_deform[time_step]:\n",
    "#                 supported_data_qubits = list(np.where(hx[X_ancilla_index - n - n_Z_ancilla,:] == 1)[0])\n",
    "                X_ancilla_index = (X_ancilla_indices+X_ancilla_indicesM)[j]\n",
    "                data_index = scheduling_X_deform[time_step][j]\n",
    "                # data_index = supported_data_qubits[i]\n",
    "                circuit_stab_meas_rep2.append(\"CX\", [X_ancilla_index, data_index])\n",
    "                if data_index in idling_data_indices:\n",
    "                    idling_data_indices.pop(idling_data_indices.index(data_index))\n",
    "            circuit_stab_meas_rep2.append(\"DEPOLARIZE1\", idling_data_indices, (error_params['p_deg'])) # idling errors for qubits that are not being checked\n",
    "            circuit_stab_meas_rep2.append(\"TICK\")\n",
    "        circuit_stab_meas_rep2.append(\"DEPOLARIZE1\", Z_ancilla_indices+Z_ancilla_indicesM, (error_params['p_state_p'])) # Add the state preparation error\n",
    "        circuit_stab_meas_rep2.append(\"TICK\")\n",
    "        circuit_stab_meas_rep2.append(\"DEPOLARIZE1\", data_indices+ data_indicesancilla , (error_params['p_deg']))\n",
    "        for time_step in range(len(scheduling_Z_deform)):\n",
    "            idling_qubits = data_indices+ data_indicesancilla + Z_ancilla_indices+Z_ancilla_indicesM\n",
    "            idling_data_indices = list(copy.deepcopy(data_indices+data_indicesancilla))\n",
    "            #circuit_stab_meas_rep2.append(\"DEPOLARIZE1\", idling_qubits, (error_params['p_idling_gate']))\n",
    "            for j in scheduling_Z_deform[time_step]:\n",
    "#                 supported_data_qubits = list(np.where(hz[Z_ancilla_index - n,:] == 1)[0])\n",
    "                Z_ancilla_index = (Z_ancilla_indices+Z_ancilla_indicesM)[j]\n",
    "                data_index = scheduling_Z_deform[time_step][j]\n",
    "                # data_index = supported_data_qubits[i]\n",
    "                circuit_stab_meas_rep2.append(\"CX\", [data_index, Z_ancilla_index])\n",
    "                if data_index in idling_data_indices:\n",
    "                    idling_data_indices.pop(idling_data_indices.index(data_index))\n",
    "            circuit_stab_meas_rep2.append(\"DEPOLARIZE1\", idling_data_indices, (error_params['p_deg'])) # idling errors for qubits that are not being checked\n",
    "            circuit_stab_meas_rep2.append(\"TICK\")\n",
    "        circuit_stab_meas_rep2.append(\"DEPOLARIZE1\", data_indices+ data_indicesancilla , (error_params['p_deg']))\n",
    "        # Measure the ancillas\n",
    "        circuit_stab_meas_rep2.append(\"TICK\")\n",
    "        circuit_stab_meas_rep2.append(\"H\", X_ancilla_indices+ X_ancilla_indicesM)\n",
    "        circuit_stab_meas_rep2.append(\"DEPOLARIZE1\", Z_ancilla_indices+Z_ancilla_indicesM+X_ancilla_indices+ X_ancilla_indicesM, (error_params['p_m'])) # Add the measurement error\n",
    "        # circuit_final_mea.append(\"DEPOLARIZE1\", data_indices, (error_params['p_i'])) # Add the idling errors on the data qubits during the measurement of X ancillas\n",
    "        circuit_stab_meas_rep2.append(\"TICK\")\n",
    "        circuit_stab_meas_rep2.append(\"MR\", Z_ancilla_indices+Z_ancilla_indicesM )\n",
    "        circuit_stab_meas_rep2.append(\"MR\", X_ancilla_indices+X_ancilla_indicesM)\n",
    "        #circuit_stab_meas_rep1.append(\"RX\", X_ancilla_indices+X_ancilla_indicesM)\n",
    "        circuit_stab_meas_rep2.append(\"SHIFT_COORDS\", [], (1))   \n",
    "        for i in range(len(X_ancilla_indices)+len(X_ancilla_indicesM)):\n",
    "            circuit_stab_meas_rep2.append(\"DETECTOR\", [stim.target_rec(- len(X_ancilla_indices)-len(X_ancilla_indicesM) + i), \n",
    "                                            stim.target_rec(- len(X_ancilla_indices)-len(X_ancilla_indicesM) + i - len(Z_ancilla_indices) -len(Z_ancilla_indicesM)- len(X_ancilla_indices)-len(X_ancilla_indicesM))], (0))\n",
    "        circuit_stab_meas_rep2.append(\"TICK\")\n",
    "###########################################################################################d_T parity check measurement of both the memory code and surface code\n",
    "        circuit_stab_meas_Hx3 = stim.Circuit()\n",
    "        circuit_stab_meas_Hx3.append(\"DEPOLARIZE1\",  data_indicesancilla, (error_params['p_m']))\n",
    "        circuit_stab_meas_Hx3.append(\"MR\", data_indicesancilla)   \n",
    "        circuit_stab_meas_Hx3.append(\"TICK\")\n",
    "    # measurement the X ancillas\n",
    "    # # Initialize the X ancillas to the + state\n",
    "        circuit_stab_meas_Hx3.append(\"H\", X_ancilla_indices)\n",
    "        circuit_stab_meas_Hx3.append(\"DEPOLARIZE1\", X_ancilla_indices, (error_params['p_state_p'])) \n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "    #circuit_stab_meas_Hx3.append(\"DEPOLARIZE1\", X_ancilla_indices, (error_params['p_H'])) # Add the state preparation error\n",
    "    #ircuit_stab_meas_rep2.append(\"DEPOLARIZE1\", data_indices, (error_params['p_i'])) # Add the idling errors on the data qubits during the preparation for X ancillas\n",
    "        circuit_stab_meas_Hx3.append(\"TICK\")\n",
    "        circuit_stab_meas_Hx3.append(\"DEPOLARIZE1\", data_indices , (error_params['p_idling_gate']))\n",
    "    # Apply CX gates for the X stabilizers\n",
    "        for time_step in range(len(scheduling_X)):\n",
    "                     idling_qubits = data_indices + X_ancilla_indices\n",
    "        #circuit_stab_meas_Hx3.append(\"DEPOLARIZE1\", idling_qubits, (error_params['p_idling_gate']))\n",
    "                     idling_data_indices = list(copy.deepcopy(data_indices))\n",
    "                     for j in scheduling_X[time_step]:\n",
    "    #                 supported_data_qubits = list(np.where(hx[X_ancilla_index - n - n_Z_ancilla,:] == 1)[0])\n",
    "                           X_ancilla_index = X_ancilla_indices[j]\n",
    "                           data_index = scheduling_X[time_step][j]\n",
    "            # data_index = supported_data_qubits[i]\n",
    "                           circuit_stab_meas_Hx3.append(\"CX\", [X_ancilla_index, data_index])\n",
    "                           if data_index in idling_data_indices:\n",
    "                                  idling_data_indices.pop(idling_data_indices.index(data_index))\n",
    "                     circuit_stab_meas_Hx3.append(\"DEPOLARIZE1\", idling_data_indices, (error_params['p_idling_gate'])) # idling errors for qubits that are not being checked\n",
    "                     circuit_stab_meas_Hx3.append(\"TICK\")\n",
    "\n",
    "    # meausure the Z ancillas\n",
    "    ## initialize the Z ancillas\n",
    "        circuit_stab_meas_Hx3.append(\"DEPOLARIZE1\", Z_ancilla_indices, (error_params['p_state_p'])) # Add the state preparation error\n",
    "        circuit_stab_meas_Hx3.append(\"DEPOLARIZE1\", data_indices, (error_params['p_idling_gate'])) # Add the idling errors on the data qubits during the preparation for Z ancillas\n",
    "        circuit_stab_meas_Hx3.append(\"TICK\")\n",
    "    # Appy CX gates for the Z stabilziers\n",
    "    #circuit_stab_meas_Hx3.append(\"DEPOLARIZE1\",  data_indices + Z_ancilla_indices, (error_params['p_idling_gate']))\n",
    "        for time_step in range(len(scheduling_Z)):\n",
    "                  idling_qubits = data_indices + Z_ancilla_indices\n",
    "        #circuit_stab_meas_Hx3.append(\"DEPOLARIZE1\", idling_qubits, (error_params['p_idling_gate']))\n",
    "                  idling_data_indices = list(copy.deepcopy(data_indices))\n",
    "                  for j in scheduling_Z[time_step]:\n",
    "    #                 supported_data_qubits = list(np.where(hz[Z_ancilla_index - n,:] == 1)[0])\n",
    "                       Z_ancilla_index = Z_ancilla_indices[j]\n",
    "                       data_index = scheduling_Z[time_step][j]\n",
    "            # data_index = supported_data_qubits[i]\n",
    "                       circuit_stab_meas_Hx3.append(\"CX\", [data_index, Z_ancilla_index])\n",
    "                       if data_index in idling_data_indices:\n",
    "                                 idling_data_indices.pop(idling_data_indices.index(data_index))\n",
    "                  circuit_stab_meas_Hx3.append(\"DEPOLARIZE1\", idling_data_indices, (error_params['p_idling_gate'])) # idling errors for qubits that are not being checked\n",
    "                  circuit_stab_meas_Hx3.append(\"TICK\")\n",
    "         \n",
    "        circuit_stab_meas_Hx3.append(\"DEPOLARIZE1\", data_indices , (error_params['p_idling_gate']))\n",
    "    # Measure the ancillas\n",
    "        circuit_stab_meas_Hx3.append(\"H\", X_ancilla_indices)\n",
    "    #circuit_stab_meas_Hx3.append(\"DEPOLARIZE1\",  X_ancilla_indices, (error_params['p_H']))\n",
    "        circuit_stab_meas_Hx3.append(\"DEPOLARIZE1\",  Z_ancilla_indices +X_ancilla_indices, (error_params['p_m']))# Add the measurement error\n",
    "        circuit_stab_meas_Hx3.append(\"TICK\")\n",
    "    # circuit_stab_meas_Hx3.append(\"DEPOLARIZE1\", data_indices, (error_params['p_i'])) # Add the idling errors on the data qubits during the measurement of X ancillas\n",
    "        circuit_stab_meas_Hx3.append(\"MR\", Z_ancilla_indices + X_ancilla_indices)\n",
    "    #circuit_stab_meas_Hx3.append(\"SHIFT_COORDS\", [], (1))\n",
    "        for i in range(len(X_ancilla_indices)):\n",
    "            circuit_stab_meas_Hx3.append(\"DETECTOR\", [stim.target_rec(- len(X_ancilla_indices) + i), \n",
    "                                        stim.target_rec(  i- len(X_ancilla_indices) - len(Z_ancilla_indices)-len(data_indicesancilla) - len(X_ancilla_indices)-len(X_ancilla_indicesM) )], (0))\n",
    "        circuit_stab_meas_Hx3.append(\"TICK\")\n",
    "\n",
    "\n",
    "############################################################################### a transversal readout\n",
    "        circuit_final_meas_f = stim.Circuit()\n",
    "#         circuit_final_meas_f.append(\"DEPOLARIZE1\", data_indices, (1*pz)) # for debug\n",
    "        circuit_final_meas_f.append(\"DEPOLARIZE1\",  data_indices, (error_params['p_m'])) # Add the measurement error\n",
    "        \n",
    "        circuit_final_meas_f.append(\"MX\", data_indices)\n",
    "        circuit_final_meas_f.append(\"TICK\")\n",
    "        circuit_final_meas_f.append(\"SHIFT_COORDS\", [], (1))\n",
    "        # Obtain the syndroms\n",
    "        for i in range(len(X_ancilla_indices)):\n",
    "            supported_data_indices = list(np.where(hx[i,:] == 1)[0])\n",
    "            rec_indices = []\n",
    "            for data_index in supported_data_indices:\n",
    "                rec_indices.append(- len(data_indices) + data_index)\n",
    "            rec_indices.append(- len(X_ancilla_indices)+ i - len(data_indices))\n",
    "            circuit_final_meas_f.append(\"Detector\", [stim.target_rec(rec_index) for rec_index in rec_indices], (0))\n",
    "        # Obtain the logical measurements result\n",
    "        for i in range(len(J_X)):\n",
    "            logical_X_qubit_indices = list(np.where(J_X[i,:] == 1)[0])\n",
    "            \n",
    "            circuit_final_meas_f.append(\"OBSERVABLE_INCLUDE\", \n",
    "                               [stim.target_rec(- len(data_indices) + data_index) for data_index in logical_X_qubit_indices],\n",
    "                               (i+2)) \n",
    "        noisy_circuit =circuit_stab_meas_repHxHx+ circuit_stab_meas_rep1+(num_rep-1)*circuit_stab_meas_rep2 +circuit_stab_meas_Hx3+(num_rep-1)*circuit_stab_meas_Hx2\n",
    "        circuit_stea =  circuit_init +circuit_stab_meas\n",
    "        noisy_circuit1 = AddCXError(noisy_circuit, 'DEPOLARIZE2(%f)' % error_params[\"p_CX\"])\n",
    "        noisy_circuitall = circuit_stea+noisy_circuit1 + circuit_final_meas_f\n",
    "\n",
    "    \n",
    "        return noisy_circuitall   \n",
    "def AddCXError(circuit:stim.Circuit, error_instruction:str) -> stim.Circuit:\n",
    "    circuit_str = str(circuit)    \n",
    "    ## Find all the unique cx instructions\n",
    "    cx_instructions = re.findall('CX.*\\n', circuit_str)\n",
    "    unique_cx_instructions = list(set(cx_instructions))\n",
    "    unique_cx_instructions\n",
    "    \n",
    "    ## Add gate errors after each cx instruction\n",
    "    for cx_ins in unique_cx_instructions:\n",
    "        circuit_str = circuit_str.replace(cx_ins, cx_ins + \n",
    "                                      cx_ins.replace('CX', error_instruction))\n",
    "    \n",
    "    modified_circuit = stim.Circuit(circuit_str)\n",
    "    \n",
    "\n",
    "    return modified_circuit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6343a19f-4234-4ca2-a78c-54dd93a9f5dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:42: SyntaxWarning: invalid escape sequence '\\d'\n",
      "<>:48: SyntaxWarning: invalid escape sequence '\\d'\n",
      "<>:42: SyntaxWarning: invalid escape sequence '\\d'\n",
      "<>:48: SyntaxWarning: invalid escape sequence '\\d'\n",
      "/tmp/ipykernel_45593/2978811094.py:42: SyntaxWarning: invalid escape sequence '\\d'\n",
      "  non_e_pattern = \"\\d+\\.\\d+\"\n",
      "/tmp/ipykernel_45593/2978811094.py:48: SyntaxWarning: invalid escape sequence '\\d'\n",
      "  non_e_matches = re.findall(\"\\d+\\.\\d+\", error_list[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "我好帥\n",
      "yanzheng\n",
      "[]\n",
      "461\n",
      "49\n",
      "171\n",
      "(3229, 26714)\n",
      "10893.674940347672\n",
      "Case 1 Results:\n",
      "[[0.24594000000000002]]\n",
      "Case 2 Results:\n",
      "[[0.24929]]\n",
      "Case 3 Results:\n",
      "[[0.0]]\n",
      "Case 4 Results:\n",
      "[[0.061180000000000005]]\n",
      "Case 5 Results:\n",
      "[[0.25366999999999995]]\n",
      "Case 6 Results:\n",
      "[[0.25031]]\n",
      "Case 7 Results:\n",
      "[[0.0]]\n",
      "Case 8 Results:\n",
      "[[0.0]]\n",
      "Case 9 Results:\n",
      "[[0.06369000000000001]]\n",
      "Case 10 Results:\n",
      "[[0.0]]\n",
      "Case 11 Results:\n",
      "[[0.0]]\n",
      "Case 12 Results:\n",
      "[[0.0]]\n",
      "Case 13 Results:\n",
      "[[0.0]]\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing as mp\n",
    "import numpy as np\n",
    "import time\n",
    "import bposd\n",
    "from ldpc.codes import ring_code\n",
    "from bposd.hgp import hgp\n",
    "from bposd import bposd_decoder\n",
    "import multiprocessing as mp\n",
    "from bposd.css import css_code\n",
    "import sys\n",
    "sys.path.append('./src/')\n",
    "from scipy import sparse\n",
    "from ldpc.codes import rep_code\n",
    "from pymatching import Matching\n",
    "import time\n",
    "import secrets\n",
    "def GenFaultHyperGraph1(detector_error_model:str, num_logicals:int):\n",
    "    # if the error model string starts with \"repeat\" block, remove it\n",
    "    \n",
    "    items = detector_error_model.split('\\n')\n",
    "    errors = [item for item in items if 'error' in item]\n",
    "    detectors = [item for item in items if 'detector' in item and 'shift' not in item]\n",
    "    shifts_indices = np.where(np.array(items) == 'shift_detectors(1) 0')[0] - len(errors) + 1\n",
    "    num_detectors_each_cycle = []\n",
    "    for i in range(len(shifts_indices)):\n",
    "        if i == 0:\n",
    "            None\n",
    "        else:\n",
    "            num_detectors_each_cycle.append(shifts_indices[i] - shifts_indices[i - 1] - 1)\n",
    "    num_detectors_each_cycle.append(len(detectors) - np.sum(num_detectors_each_cycle))\n",
    "\n",
    "    layered_dectectors = []\n",
    "    layered_dectectors.append(detectors[:num_detectors_each_cycle[0]]) # first layer\n",
    "    layered_dectectors.append(detectors[-num_detectors_each_cycle[-1]:]) # last layer\n",
    "    \n",
    "    layered_dectectors = [[dectector_str.split()[1] for dectector_str in dectectors_each_layer] for dectectors_each_layer in layered_dectectors]\n",
    "    layered_errors = [[] for i in range(2)]\n",
    "    for error in errors:\n",
    "        error_list = error.split()\n",
    "        #error_p = float(re.findall(\"\\d+\\.\\d+\", error_list[0])[0])\n",
    "        non_e_pattern = \"\\d+\\.\\d+\"\n",
    "        e_pattern = r'([\\d]+\\.[\\d]+e-[\\d]+)'\n",
    "        e_matches = re.findall(e_pattern, error_list[0])\n",
    "        if e_matches:\n",
    "            error_p = float(e_matches[0])\n",
    "        else:\n",
    "            non_e_matches = re.findall(\"\\d+\\.\\d+\", error_list[0])\n",
    "            error_p = float(non_e_matches[0])\n",
    "\n",
    "        detectors = error_list[1:]\n",
    "        \n",
    "        flipped_logicals = [item for item in error_list if 'L' in item]\n",
    "        occupied_layers = [j for j in range(len(layered_dectectors)) if set(detectors).intersection(set(layered_dectectors[j]))]\n",
    "        \n",
    "        if occupied_layers != []:\n",
    "            layer = occupied_layers[0]\n",
    "            detectors = list(set(detectors).intersection(layered_dectectors[layer]))\n",
    "            error_dict = {'layer':layer, 'p':error_p, 'detectors':detectors, 'logicals':flipped_logicals}\n",
    "            layered_errors[layer].append(error_dict)\n",
    "    \n",
    "    # obtain the check matrix for each layer\n",
    "    H_list = []\n",
    "    for error_each_layer, detector_each_layer in zip(layered_errors, layered_dectectors):\n",
    "        H_each_layer = np.zeros([len(detector_each_layer), len(error_each_layer)])\n",
    "        for i in range(len(detector_each_layer)):\n",
    "            for j in range(len(error_each_layer)):\n",
    "                if detector_each_layer[i] in error_each_layer[j]['detectors']:\n",
    "                    H_each_layer[i,j] = 1\n",
    "        H_list.append(H_each_layer)\n",
    "    \n",
    "    # obtain the channel probability for each layer\n",
    "    channel_prob_list = [[error['p'] for error in error_each_layer] for error_each_layer in layered_errors]\n",
    "\n",
    "    # obtain the matrix for the flipped logicals for each layer\n",
    "    L_list = []\n",
    "    logicals = ['L'+str(i) for i in range(num_logicals)]\n",
    "    for error_each_layer in layered_errors:\n",
    "        L_each_layer = np.zeros([len(logicals), len(error_each_layer)])\n",
    "        for i in range(len(logicals)):\n",
    "            for j in range(len(error_each_layer)):\n",
    "                if logicals[i] in error_each_layer[j]['logicals']:\n",
    "                    L_each_layer[i,j] = 1\n",
    "        L_list.append(L_each_layer)\n",
    "    \n",
    "#     return layered_errors, layered_dectectors \n",
    "    return H_list, L_list, channel_prob_list\n",
    "def hypergraph_product_code1(H1, H2):\n",
    "    # 获取矩阵的形状\n",
    "    m1, n1 = H1.shape\n",
    "    m2, n2 = H2.shape\n",
    "\n",
    "    # 构造单位矩阵\n",
    "    I1 = np.eye(n1, dtype=int)\n",
    "    I2 = np.eye(n2, dtype=int)\n",
    "    I3 = np.eye(m1, dtype=int)\n",
    "    I4 = np.eye(m2, dtype=int)\n",
    "    vectors = np.zeros(n2,dtype=int)\n",
    "    vectors[0]=1\n",
    "    # 构造 H_X\n",
    "    HZ = np.hstack((np.kron(I2,H1)%2, np.kron(H2.T,I3)%2))\n",
    "    LX = np.hstack((np.kron(vectors,np.ones(n1,dtype=int))%2, np.zeros(m2*m1,dtype=int)%2))\n",
    "    LX = np.atleast_2d(LX)    \n",
    "    # 构造 H_Z\n",
    "    HX = np.hstack((np.kron(H2,I1)%2, np.kron(I4,H1.T)%2))\n",
    "    \n",
    "    return HX, HZ,LX\n",
    "# LFR function\n",
    "def LFR(logical_vals):\n",
    "    failures = [1 * logical.any() for logical in logical_vals]\n",
    "    LFP = np.sum(failures) / 100\n",
    "    return LFP\n",
    "Lall = [4]\n",
    "\n",
    "def generate_channel_matrix(m, length, channel_probs, seed):\n",
    "    \"\"\"\n",
    "    生成一个 m行×length列 的0/1矩阵，其中第j列的每个元素为1的概率是 channel_probs[j]\n",
    "    \n",
    "    参数:\n",
    "        m: 行数\n",
    "        length: 列数（需与channel_probs长度一致）\n",
    "        channel_probs: 概率向量，每个元素为0~1之间的浮点数\n",
    "        seed: 随机数种子（默认为None，表示不设置种子）\n",
    "    \n",
    "    返回:\n",
    "        binary_matrix: m×length的二值矩阵（0或1）\n",
    "    \"\"\"\n",
    "    assert len(channel_probs) == length, \"channel_probs的长度必须等于length\"\n",
    "    \n",
    "    # 设置随机数种子\n",
    "    \n",
    "    np.random.seed(seed)\n",
    "    \n",
    "    # 生成均匀分布随机矩阵，并通过广播与channel_probs逐列比较\n",
    "    rand_matrix = np.random.rand(m, length)\n",
    "    binary_matrix = (rand_matrix < channel_probs).astype(int)\n",
    "    return binary_matrix\n",
    "circuit_error_params = {\"p_i\": 0, \"p_state_p\": 1, \"p_m\": 1, \"p_CX\": 1, \"p_idling_gate\": 1,\"p_H\": 0,\"p_deg\": 1}\n",
    "eval_logical_type = 'Z'\n",
    "# circuit_type = 'colorproduct'\n",
    "circuit_type = 'coloration'\n",
    "def process_sample_batch(num_qubits,eval_p,h,L,num_rep,channel_probs, circuit_error_params, num_samples, start_index, batch_size,circuit_type,D=1,seed=None):\n",
    "    \"\"\"\n",
    "    处理一批采样任务，每个批次执行 `batch_size` 次采样。\n",
    "    \"\"\"\n",
    "\n",
    "    #matching_decoding= Matching_Decoding()\n",
    "    #matching_decoding.from_detector_error_model(dem, num_logicals)\n",
    "    #logical_correction = matching_decoding.decode_batch1(detector_vals)\n",
    "    #corrected_logical_vals = (logical_vals + logical_correction) % 2\n",
    "    seed= secrets.randbelow(2**32)\n",
    "    decoder_params = {'max_iter':int(1000), 'bp_method': 'min_sum', \n",
    "                      'ms_scaling_factor': 0.9, 'osd_method': \"osd_cs\", 'osd_order': 5}\n",
    "    max_iter = decoder_params['max_iter']\n",
    "    bp_method =decoder_params['bp_method']\n",
    "    ms_scaling_factor = decoder_params['ms_scaling_factor']\n",
    "    osd_method = decoder_params['osd_method']\n",
    "    osd_order = decoder_params['osd_order']\n",
    "    bposd_decoding =BpOsdDecoder(\n",
    "                    h,\n",
    "                    channel_probs=channel_probs,\n",
    "                    max_iter=max_iter,\n",
    "                    bp_method=bp_method,\n",
    "                    ms_scaling_factor=ms_scaling_factor,\n",
    "                    osd_method=osd_method,\n",
    "                    osd_order=osd_order, )  \n",
    "\n",
    "\n",
    " \n",
    "\n",
    "    sample = generate_channel_matrix(batch_size,h.shape[1], channel_probs,seed)\n",
    "    case3_count =0\n",
    "    case2_count =0 \n",
    "    case1_count =0\n",
    "    case4_count =0\n",
    "    case5_count =0\n",
    "    case6_count = 0  \n",
    "    case7_count = 0  \n",
    "    case8_count = 0   \n",
    "    case9_count = 0   \n",
    "    case10_count = 0  \n",
    "    case11_count = 0  \n",
    "    case12_count = 0  \n",
    "    case13_count = 0\n",
    "\n",
    "    for i in range(sample.shape[0]):\n",
    "\n",
    "       vector = sample[i,:]\n",
    "       vector = np.array(vector)\n",
    "       syn = h@vector.T%2\n",
    "\n",
    "\n",
    "       \n",
    "       error_estimate = bposd_decoding.decode(syn.T)\n",
    "       corrected_vector = (vector + error_estimate) % 2\n",
    "       predicted_observables = (corrected_vector @ L.T) % 2\n",
    "       obs = predicted_observables\n",
    "       if (obs[-3]==0) and (obs[5]==1):\n",
    "            case1_count += 1\n",
    "       if (obs[-4]==0) and (obs[4]==1):\n",
    "            case2_count += 1\n",
    "       if((obs[-4]==0) and (obs[4]==1)) and ((obs[-3]==0) and (obs[5]==1)):\n",
    "       #ocZ_j - ocZ_j \\cap ocM_j and noZ_j\n",
    "            case4_count += 1\n",
    "       if (obs[-4]+obs[4])%2== 1 :#ocZ_j - ocZ_j \\cap ocM_j and noZ_j\n",
    "            case5_count += 1\n",
    "        #############j = 2\n",
    "       if (obs[-3]+obs[5])%2== 1:#(Z_j)-(Z_j)\\cap(oc_j)\n",
    "            case6_count += 1        \n",
    "       ####################\n",
    "       if ((obs[-4]+obs[4])%2== 1) and ((obs[-3]+obs[5])%2 == 1):\n",
    "            case9_count += 1\n",
    "    # 计算三种情况的比率（分母根据实际样本量调整）\n",
    "    total = sample.shape[0]\n",
    "    return [\n",
    "        case1_count/total,\n",
    "        case2_count/total,\n",
    "        case3_count/total,\n",
    "        case4_count/total,\n",
    "        case5_count/total,\n",
    "        case6_count/total,  \n",
    "        case7_count/total,   \n",
    "        case8_count/total,  \n",
    "        case9_count/total,   \n",
    "        case10_count/total,  \n",
    "        case11_count/total,\n",
    "        case12_count/total,\n",
    "        case13_count/total\n",
    "    ]\n",
    "\n",
    "    \n",
    "\n",
    "def parallel_sampling(num_qubit,eval_p, H,L,num_rep,channel_prob, circuit_error_params, circuit_type, D, num_samples, batch_size, num_processes=None):\n",
    "    \"\"\"\n",
    "    对单个 `eval_p` 进行 8000 次采样，并行化每次采样任务。\n",
    "    \"\"\"\n",
    "    num_samples =100000\n",
    "    batch_size =2000\n",
    "    num_batches = num_samples // batch_size\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "    with mp.Pool(50) as pool:\n",
    "        results = pool.starmap(process_sample_batch, \n",
    "                              [(num_qubit,eval_p, H,L,num_rep,channel_prob, circuit_error_params,num_samples , i * batch_size, batch_size,circuit_type, D) \n",
    "                               for i in range(num_batches)])\n",
    "    \n",
    "    all_case = [[] for _ in range(13)]\n",
    "    for r in results:\n",
    "        for i in range(13):\n",
    "            all_case[i].append(r[i])\n",
    "    \n",
    "    # 合并结果\n",
    "    LFR_cases = [np.mean(case) for case in all_case]\n",
    "    return LFR_cases\n",
    "eval_ps = np.array([0.0017])\n",
    "#eval_ps = np.array([0.009])\n",
    "\n",
    "#### different code\n",
    "##############################################\n",
    "\n",
    "ell, m = 15, 3\n",
    "code = [9, 1, 2, 0, 2, 7]  # 需验证参数\n",
    "H_X, H_Z = construct_ldpc(ell, m, code)\n",
    "\n",
    "H_X = H_X.astype(np.uint8) \n",
    "H_Z = H_Z.astype(np.uint8)\n",
    "\n",
    "H_X1= gf2_rref(H_X)\n",
    "H_X1 = remove_zero_rows(H_X1)\n",
    "\n",
    "H_Z1= gf2_rref(H_Z)\n",
    "H_Z1 = remove_zero_rows(H_Z1)\n",
    "LX,LZ,I_s = CSS_code_Logical(H_X1,H_Z1)\n",
    "LX = LX.astype(np.uint8)\n",
    "\n",
    "L =10\n",
    "J_X_1 = LX[-2:,]\n",
    "##############################\n",
    "\n",
    "h = rep_code(2)\n",
    "h1 = h.toarray()\n",
    "D=10\n",
    "num_rep = 10\n",
    "surface_codehx,surface_codehz,surface_codelx =hypergraph_product_code1(H1=h1,H2=h1)   \n",
    "hx=surface_codehx\n",
    "hz=surface_codehz\n",
    "lx=surface_codelx\n",
    "hx=hx.astype(np.uint8)\n",
    "hz=hz.astype(np.uint8)\n",
    "\n",
    "num_logicals = LX.shape[0]+4\n",
    "num_qubit = LX.shape[1]+2*lx.shape[1]\n",
    "eval_pm = 0.001 \n",
    "qec_circuit = QECCircuit_OneStage(H_Z,H_X,J_X_1,LX,I_s,hz,hx,lx,num_rep, circuit_error_params, eval_pm,circuit_type,D)\n",
    "\n",
    "dem = qec_circuit.detector_error_model(flatten_loops=True)\n",
    "\n",
    "\n",
    "H, LX, channel_prob = GenDecodingGraphs(str(dem), num_logicals=num_logicals)\n",
    "H_List,L_List,channel_prob_List = GenFaultHyperGraph1(str(dem), num_logicals=num_logicals)\n",
    "H = H.astype(np.uint8)\n",
    "print(H.shape)\n",
    "H_List = np.array(H_List[0])\n",
    "L_List = np.array(L_List[0])\n",
    "LX = LX.astype(np.uint8)\n",
    "m = -L_List.shape[1]+LX.shape[1]\n",
    "L_List = np.hstack((L_List,np.zeros((L_List.shape[0],m),dtype=int)))\n",
    "L_ocZ = (L_List [-4:,:]).astype(np.uint8)\n",
    "\n",
    "LX = np.vstack((L_ocZ,LX))\n",
    "channel_prob = np.array(channel_prob) \n",
    "LFPPP = [[] for _ in range(13)]\n",
    "\n",
    "start_time = time.time()\n",
    "for eval_p in eval_ps:\n",
    "   \n",
    "    LFR_all_results = [[] for _ in range(13)]\n",
    "    for L in Lall:\n",
    "\n",
    "      channel_probs = (eval_p / eval_pm) * channel_prob\n",
    "      channel_probs = list(channel_probs)\n",
    "      LFR_cases= parallel_sampling(num_qubit,eval_p,H,LX,num_rep,channel_probs,circuit_error_params, circuit_type, D, num_samples=100000, batch_size=2000, num_processes=mp.cpu_count())    \n",
    "      for i in range(13):\n",
    "            LFR_all_results[i].append(LFR_cases[i])\n",
    "    \n",
    "    # 存储到全局结果\n",
    "    for i in range(13):\n",
    "        LFPPP[i].append(LFR_all_results[i])\n",
    "elapsed_time = time.time() - start_time\n",
    "print(elapsed_time)\n",
    "for i in range(13):\n",
    "    print(f\"Case {i+1} Results:\")\n",
    "    print(LFPPP[i])\n",
    "LFPPP = [[] for _ in range(13)]\n",
    "eval_ps = np.array([0.001])\n",
    "for eval_p in eval_ps:\n",
    "   \n",
    "    LFR_all_results = [[] for _ in range(13)]\n",
    "    for L in Lall:\n",
    "\n",
    "      channel_probs = (eval_p / eval_pm) * channel_prob\n",
    "      channel_probs = list(channel_probs)\n",
    "      LFR_cases= parallel_sampling(num_qubit,eval_p,H,LX,num_rep,channel_probs,circuit_error_params, circuit_type, D, num_samples=100000, batch_size=2000, num_processes=mp.cpu_count())    \n",
    "      for i in range(13):\n",
    "            LFR_all_results[i].append(LFR_cases[i])\n",
    "    \n",
    "    for i in range(13):\n",
    "        LFPPP[i].append(LFR_all_results[i])\n",
    "\n",
    "for i in range(13):\n",
    "    print(f\"Case {i+1} Results:\")\n",
    "    print(LFPPP[i])\n",
    "LFPPP = [[] for _ in range(13)]\n",
    "eval_ps = np.array([0.001,0.0012,0.0015,0.0017,0.002,0.0023,0.0025,0.003])\n",
    "for eval_p in eval_ps:\n",
    "   \n",
    "    LFR_all_results = [[] for _ in range(13)]\n",
    "    for L in Lall:\n",
    "\n",
    "      channel_probs = (eval_p / eval_pm) * channel_prob\n",
    "      channel_probs = list(channel_probs)\n",
    "      LFR_cases= parallel_sampling(num_qubit,eval_p,H,LX,num_rep,channel_probs,circuit_error_params, circuit_type, D, num_samples=100000, batch_size=2000, num_processes=mp.cpu_count())    \n",
    "      for i in range(13):\n",
    "            LFR_all_results[i].append(LFR_cases[i])\n",
    "    \n",
    "    for i in range(13):\n",
    "        LFPPP[i].append(LFR_all_results[i])\n",
    "\n",
    "for i in range(13):\n",
    "    print(f\"Case {i+1} Results:\")\n",
    "    print(LFPPP[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "760a486a-cb29-4ef7-a381-767365b25f63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63b7a454-a75e-4ca9-8409-fd5e5ed7cac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "different code\n",
    "#################################################\n",
    "x = symbols('x')\n",
    "n =24\n",
    "k = 6\n",
    "\n",
    "a_x = 1 + x**2+x**8 + x**15 \n",
    "b_x = 1 + x**2+x**12+ x**17\n",
    "A = polynomial_to_circulant(a_x, n)\n",
    "B = polynomial_to_circulant(b_x, n)\n",
    "\n",
    "H_X= np.hstack((A,B))\n",
    "\n",
    "H_X1= gf2_rref(H_X)\n",
    "H_X1 = remove_zero_rows(H_X1)\n",
    "H_Z= np.hstack((B.T,A.T))\n",
    "H_Z1= gf2_rref(H_Z)\n",
    "H_Z1 = remove_zero_rows(H_Z1)\n",
    "LX,LZ,I_s = CSS_code_Logical(H_X1,H_Z1)\n",
    "J_X_1 = LX[:2,]\n",
    "#####################################\n",
    "#################\n",
    "H_Z = block_diagonal(hz,hz)\n",
    "H_X = block_diagonal(hx,hx)\n",
    "H_X1= gf2_rref(H_X)\n",
    "H_X1 = remove_zero_rows(H_X1)\n",
    "H_Z1= gf2_rref(H_Z)\n",
    "H_Z1 = remove_zero_rows(H_Z1)\n",
    "LX,LZ,I_s = CSS_code_Logical(H_X1,H_Z1)\n",
    "\n",
    "J_X_1 = LX[:2,]\n",
    "\n",
    "################\n",
    "#################################################\n",
    "x = symbols('x')\n",
    "n =24\n",
    "k = 6\n",
    "\n",
    "a_x = 1 + x**2+x**8 + x**15 \n",
    "b_x = 1 + x**2+x**12+ x**17\n",
    "A = polynomial_to_circulant(a_x, n)\n",
    "B = polynomial_to_circulant(b_x, n)\n",
    "\n",
    "H_X= np.hstack((A,B))\n",
    "\n",
    "H_X1= gf2_rref(H_X)\n",
    "H_X1 = remove_zero_rows(H_X1)\n",
    "H_Z= np.hstack((B.T,A.T))\n",
    "H_Z1= gf2_rref(H_Z)\n",
    "H_Z1 = remove_zero_rows(H_Z1)\n",
    "LX,LZ,I_s = CSS_code_Logical(H_X1,H_Z1)\n",
    "J_X_1 = LX[:2,]\n",
    "#####################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94a58284-3438-4171-9d6b-456320106001",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08e503a5-726b-4e50-861a-5cd2b7cd5317",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
